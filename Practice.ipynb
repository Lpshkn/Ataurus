{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://habr.com/ru/company/cognitivepilot/blog/514678/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = request.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_post = soup.find('div', 'post__text').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' А ведь в прошлом году это делали senior-разработчики. Возможно, вы помните, что мы говорили про то, как можно сильно улучшить работу обычного сельскохозяйственного комбайна, если использовать нейросетки для распознавания культур и препятствий и робота для автопилотирования. Всё это (кроме процессоров Nvidia и ещё части железа) — наша разработка. А радость в том, что в некоторых южных регионах страны закончилась уборочная страда, и наши комбайны показали себя лучше, чем ожидалось. Слава роботам! В этом году мы поставили несколько сотен блоков из мощного графического ядра (для нейросетей), камер, гидравлических насосов или CAN-модулей для подруливания. Если в прошлом году агропилоты были в опытной эксплуатации, то сейчас речь идёт уже про серийные модели. И они справились. Более того, они справились лучше, чем мы ждали. Кроме того, в релиз вошли далеко не все фичи. В релизе осталось, по сути, ядро, но одно только это позволило получить очень заметный экономический эффект. Конечно, обошлось не без сюрпризов. Но давайте расскажу более конкретно, с числами и примерами. Можно разглядеть камеру 2 Мп сверху. NVIDIA TX2 в специальном кожухе и с огромным радиатором монтируется внизу в подкабинном пространстве. Экран — в кабине. О чём идёт речь Сельскохозяйственный комбайн по сложности управления похож на церковный орган. Когда в кабине — комбайнёр и помощник, то один рулит (держит кромку), а второй управляет мотовилом, ветрами, барабанами и вообще следит за сбором. Третий в это время может делать отгрузку на ходу в грузовик, едущий рядом. Четвёртый следит за препятствиями. В эпоху СССР в кабине было двое, потом остался один. В итоге он или рулит, или собирает зерно нормально. Стоя на месте, собирать зерно нормально не выходит, поэтому он рулит. Про то, как там всё хитро закручено и почему комбайны регулярно перемалывают людей, врезаются в тракторы и бегущие через поле столбы ЛЭП, — наш первый пост. Вторая особенность — каждая из ролей, даже если выполнять её не отрываясь, очень монотонная и требует постоянной бдительности. Это как смотреть на трассу 10 часов в день при условии, что нужно поймать буквально два момента за сутки, когда нужна быстрая реакция. Третья особенность — комбайнёры часто предпочитают убирать быстрее с меньшим КПД (поскольку оплата идёт за отгруженные тонны), а не получать максимум зерна с гектара. В серию вошли фичи удержания кромки (комбайн сам следит за тем, как едет, и сам рулит) и предотвращения столкновений (комбайн внимательно смотрит по сторонам и прогнозирует движение всего, что видит, — от людей до тракторов). Тут наработки беспилотного трамвая после езды вокруг ВДНХ очень пригодились. В поле куда спокойнее с препятствиями. Про видеоаналитику есть вот здесь. Отдельное подразделение занимается обучением нейросетей (фотографированием ситуаций и разметкой данных), чтобы определять, где какая культура, как выглядит полёгшая пшеница и так далее. Поскольку обучающих выборок нет, мы ездим в поля и снимаем сами. Это важно, потому что одна и та же культура от сорта к сорту и от климата к климату отличается визуально. Ещё одно подразделение занимается разработкой железа. У нас есть радар собственной разработки для тепловозов и трамваев, но на комбайне — только камеры, потому что оснащать их нужно как можно дешевле. Сложная история — это разбор протоколов управления (иногда утерянных вместе с производителем, и тогда нужно реверсить) или же установка гидравлики для подмешивания нашего сигнала в руление. Вычислительные модули на каждом комбайне автономные. Что случилось в этом году В поля вышли не инженеры и специально обученные испытатели, а обычные работяги, для которых всё это и разрабатывалось. Они убирали реальный урожай. И да, они проверяли нашу систему на прочность, как в том анекдоте про бензопилу. Больше всего мы боялись, что именно конечные пользователи (комбайнёры) станут мешать внедрению, потому что почувствуют угрозу своей работе. Но всё обошлось успешно. Они понимают ограничения автопилота, понимают, что нужны в кабине, понимают, как он их разгружает и что именно они могут делать лучше. У них увеличивается выработка, а значит, увеличивается заработок за уборочную. Причём значительно: примерно на 10–15 %. Они хотят работать с нашим роботом в паре. В одном хозяйстве они бились за машины с ним. Человек полностью разгружен. Он включает систему, отпускает руль, в лучшем случае контролирует работу машины, в худшем — сидит в телефоне. Недели уборочной для комбайнёров — это работа-сон-работа-сон-работа. Сил ни на что не бывает в принципе, потому что за месяц нужно заработать на полгода. Наши пилоты стали рассказывать, что у них остаются силы для домашней работы. Машины стали лучше смотреть, потому что после работы хотелось не упасть и уснуть, а можно было заняться техобслуживанием. Те, кто осознанно выбирал больший рабочий день, говорили, что можно легко работать на два часа больше. Они и работали бы больше, но совсем ночью нельзя: роса. Вот пара картинок, которые соседние механизаторы увидели из своих машин и потом полезли смотреть, как всё устроено: «Сидит там, чай пьёт, гад! *** [зачем] теперь механизатор нужен?». Потом смотрели, что робот всё же может далеко не всё, и понимали, что это просто как новый комбайн с парой особенностей. И успокаивались. Есть числа: Увеличилась производительность смены по времени — комбайнёр не устаёт. Это может показаться численным преимуществом в 10–15 %, но там всё гораздо интереснее. Дело в том, что это даёт три дополнительных дня на уборку. Это значит, что если будет плохая погода (проливные дожди, в которые зерно прорастает или осыпается), то урожай не пропадёт, а будет убран целиком с куда большей вероятностью. Комбайнёр разгружен. Он может смотреть за функционалом комбайна, высотой подъёма жатки и забивкой жатки всё время. Это работа на чувствительность и навык, и раньше она не могла быть качественной из-за постоянного поворота головы в другую сторону, где кромка. Теперь мастера могут вытаскивать из машины 100 % возможной производительности. Это уменьшает себестоимость зерна. Внимания начало вполне хватать для выгрузки на ходу. Это важно, потому что не нужно ездить куда-то на край поля опустошать бункер в грузовик. Грузовик может ехать за комбайном, а комбайнёр будет сгружать в него урожай — меньше простоев, меньше пробег, больше производительность смены. Поскольку комбайн контролирует режим, наш робот защищает от ошибок. Владельцы сельхозхозяйств говорят, что теперь можно смело сажать менее опытных комбайнёров. Обычно нужно три сезона, чтобы человек набил руку (это примерно 1,6 единицы «убитой» техники). Меньше зазоры: раньше промежутки контролировал человек, и они брались с допуском на усталость (к концу смены получались очень большие непрокошенные участки). А роботу плевать, он держит норматив в любое время смены. Получается — механизаторы и руководители в один голос говорят, что работа стала проще. У кого не было перегрузчиков зерна, задумались, чтобы их докупить. В разных хозяйствах — разные дневные нормы, обычно это 20–25 гектаров. Мы видели, что спокойно ставят 30, и люди на этом не выматываются. Для кого-то это оказалось возможностью сократить парк комбайнов на следующий год: не нужно будет закупать две-три машины. Знаю, звучит очень странно, но два хозяйства (примерно из сотни) сказали, что сделают именно так. Уборочная началась с того, что Герман Греф попробовал в Песчанокопской аграрной группе (на крупной серийной партии) и сказал, что освоил за три минуты. Мы гордимся этим видео. Если президент банка справился, то работяги в полях справятся точно. Ну и если вдруг у кого-то освободится в регионе несколько сотен чиновников, то можно быстро переквалифицировать их в операторов техники. Вы задумайтесь. «Русагро» подписала контракт на 240 машин. Многие хозяйства дозаказали на следующий год комплекты на весь парк. Не без сюрпризов К слову о том, как мужики быстро освоили технику. Хозяйство взяло четыре комплекта протестировать, мы приехали, установили их на машины, сделали пусконаладку. Не до конца откалибровали одометрию, потому что для этого нужен дневной свет. Решили сделать с утра. Утром приходят установщики, а мужики на этих машинах на дефолтных настройках уже вышли в поле, всё инициализировали и снимают из кабины, что творит робот. Возможно даже, это был стрим в Инстаграме для остальных на поле. С одной стороны, конечно, хотелось сделать калибровку, а с другой — приятно, что мужики всё сами запустили и всё поднялось на настройках по умолчанию. После первых дней во многих хозяйствах в нашего робота то ли начинали верить, как во всемогущий интеллект вроде Терминатора, то ли просто тестировали на прочность. Так или иначе, в одном хозяйстве решили попробовать убирать ночью. Иногда люди думают, что робот должен думать, как человек. Были несколько разочарованы тем, что ночью он справляется хуже. Дело в том, что в боевом релизе нет ночной уборки: это требует дообучения и немного других алгоритмов обработки данных. Пока мы гарантируем нормальную ночную работу только при достаточно широком освещении (оно такое на иностранных комбайнах трёх-четырёхлетней давности почти везде), а здесь наши испытатели вышли в поле на отечественном комбайне 16-летней давности с узким мерцающим конусом света впереди. Поскольку ночную уборку большая часть хозяйств не практикует, мы отложили эту фичу на следующий год. Второе место, где были завышенные ожидания, — это сложные условия по пыли. Например, комбайны, когда идут друг за другом, поднимают облака пыли. Ветер иногда такой, что порывом тучу пыли сносит на комбайн, который сзади. Поскольку ориентируется он не по дорогущему радару, а по обычной камере, ему не видно, что впереди. Видимость в облаках пыли бывает шесть метров. В такие моменты наша система перестаёт видеть: она сигнализирует механизатору и отпускает управление. Нам даже говорили, что лидар отказал. Но лидара на комбайне нет. Механизаторы ругались: «Ну как он не видит?». В итоге именно это почему-то их успокоило насчёт работы. Человек-то помнит и понимает: до комбайна — метров 10, мы едем с такой-то скоростью, порыв пронесёт через минуту, ничего не случится, если дольше — надо вставать. И Пётр Михалыч впереди точно не встанет. Наверное. Система жизненным опытом не обладает и с Михалычем годами не бухала, поэтому она в таком случае останавливает машину и отпускает управление. Так в очередной раз человеческий интеллект побеждает бота. В релиз не вошли автоповороты. Это та фича, которая невероятно поражала всех комбайнёров, но она же оказалась самой сложной по тестированию: при огромной ширине жатки нужно строить очень много гипотез про то, что выпадает из поля зрения. На каждой машине — свои особенности. Плюс это же требует сложной системы управления с тем, чтобы задавать маршрут заранее или как-то его программировать. Мы — за естественное управление: щёлкнул рубильником робота, ведёшь машину, выходишь на поле, начинаешь убирать. Робот говорит: «Мужик, дай я порулю», щёлкаете вторым рубильником — и он рулит. Нужно повернуть — просто делаете это, ко-пилот отпускает управление, потом ищет новую кромку. Когда находит — снова просит вернуть управление. Всё интуитивно понятно и просто. В итоге поворачивать между проходами мы доверили людям. С автоматизацией ждём конца тестов на сложном рельефе. Обычно проходка — длиной до пяти километров, то есть сами повороты занимают меньше 1 % времени работы комбайнёра. Камера на комбайне одна, потому что приоритет — цена. Вторая не очень увеличивает цену, но очень увеличивает нагрузку на вычисления, а вычислительный блок на 4 Tflops — большая часть стоимости железа. Камера смотрит влево на жатку. Есть несколько экзотических схем (редко используемых в РФ), когда всё интересное происходит не только слева, но и справа. Вообще у нас две основные системы уборки: загонкой и челноком. Работа загонкой: отрезается кусок поля, и вокруг него всё обкашивают по сужающемуся прямоугольнику или кругу, стремясь к центру. Соответственно мы это делаем против часовой стрелки. Челноком: с одной стороны заезжают и ездят туда-сюда — как на принтере. Образуются пустые прогоны между проходками, но зато можно взять участок любой формы. Так вот, для полей сложной формы есть более оптимизированные схемы, которые требуют смотреть в обе стороны. Возможно, в одном из следующих релизов предложим переключение между камерами. «Канадская» схема. Потом — монтаж. В середине лета в самый разгар карантина наши комбайны впервые с прошлого года вдруг все увидели и заметили. Точнее, наверное, заметили ещё в том году, но заказывать комплекты стали прямо перед уборочной (это связано, возможно, с кредитованием хозяйств с короткими сроками). В итоге мы ездили по стране в условиях карантина, что наложило неповторимый отпечаток на работу специалистов по нейросетям. Установщики где-то сидели 14 дней, где-то ходили чуть ли не в скафандрах, но получилось справиться с 50 хозяйствами (и предстоит ещё столько же). Сталкивались с техсложностями: на некоторых зарубежных моделях (и одной российской) компоновка отсеков крайне плотная. Разница — как между заглянуть под капот «Жигулей» и заглянуть в Макбук. Из полей присылали размеры, мы срочно заказывали новые кронштейны или новые системы крепления под конкретную модель. Из-за пандемии сменили поставщика оборудования. Гидроблоки были от немецкого производителя. Они нам в марте сказали: «Приходите через четыре месяца». Это была паника, потому что от этого зависела вся история. Нашли российского производителя, они всё поняли, оказались лёгкими на подъём и сделали нам гидравлику. Оперативно, но тоже не без сюрпризов да и не без нервов при постановке задачи, конечно. Но до этого года мы не верили, что это вообще возможно в России. Что дальше Роботы убирали злаковые: пшеницу, ячмень, овёс, рожь в южных регионах. Ещё не было серийной эксплуатации на кукурузе и подсолнечнике (это позже по агрономическим срокам). Нам интересны ещё рапс и соя. Рапс — это Центральная Россия, пока там ждём уборки. Соя — Сибирь, Алтай, юг Сибири, Хабаровский край, это уже совсем скоро. Сарафанное радио не стоит на месте. За последние месяца полтора пришло около десятка очень крупных холдингов из первых 50 со своими кастомными запросами. Какие-то уже приобретают комплекты для тестирования на эту уборочную. Кто-то делает для нас собственное ТЗ и особые хотелки — мы будем думать в межсезонье. Задачи стоят подвязать мониторинг урожайности (комбайн же считает зерно в телеметрии и видит координаты, то есть можно снимать данные по урожайности участков почв до метра), мониторинг работы комбайна (отправка телеметрии в центр). Какие-то хозяйства приходят только к цифре, многим для севооборота важно, чтобы были отмечены критические точки на полях. Важно понимать годовую среднюю урожайность и оценивать каждый год «живые» деньги. Аналитика нужна для того, чтобы примерно понимать загрузку тракторов и технику: докупить или убавить. Там много нюансов вплоть до заказа ГСМ перед сезоном: это всё неприятные предоплаты. Как сказал крупный руководитель крупного хозяйства: «Мы работаем с рынком. Рынок мы не контролируем. Чтобы больше зарабатывать, можем только уменьшать себестоимость. Если не уменьшать — нас съедят тупо». Срок жизни комбайна пишут 10–12 лет (но мы часто видим 2005 год, ставили в этом году даже на 2001-й). Мы их все дооснащаем. Потому что, пока лошадка живая, на ней ездят. Когда починка становится дороже стоимости нового, берут новый. Кончается, кстати, тем, что старый комбайн становится донором запчастей для других таких же. Да, это просаженная печень и сломанные ноги, но год-два они работают. Потом всё это сгнивает. И ещё замечательное — отзывы о том, что с этой экономикой комбайн окупается быстрее. Стоит машина, например, 25 миллионов рублей (зависит от производителя и модели). В хозяйстве считают: пять лет — на отечественные машины, иномарка окупается за восемь лет. Теперь — минус год примерно. Сейчас мы закончим уборку в этом году на серийных моделях и ещё нескольких экспериментальных, сведём экономику и будем публиковаться в международных экономических обзорах. Наши модули будут ставиться как в таком виде — отдельной коробки на комбайны, так и войдут в виде интегрированных устройств в новые комбайны, если всё кончится хорошо. У нас получилось. Два с половиной года жизни команды, кажется, немного меняют мир. P.S. Если вашего агронома нет на Хабре, а ему это интересно, можно вот тут вот найти контакты: promo.cognitivepilot.com и предметно обсудить, для какого комбайна, какой конкретно набор техники нужен, сколько примерно стоит, и как это можно быстро посмотреть-испытать. P.S.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_post = re.sub(r\"[\\s]+\", r\" \", text_post)\n",
    "text_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = \"\"\"Но давайте расскажу более конкретно, с числами и примерами.\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences += \"\"\"Более того, они справились лучше, чем мы ждали.\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences += \"\"\"Тут наработки беспилотного трамвая после езды вокруг ВДНХ очень пригодились.\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences += \"\"\"Отдельное подразделение занимается обучением нейросетей (фотографированием ситуаций и разметкой данных), чтобы определять, где какая культура, как выглядит полёгшая пшеница и так далее.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sent in enumerate(sentences.split('\\n')):\n",
    "    corpus['sent{}'.format(i)] = dict((tok, 1) for tok in sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sent0': {'Но': 1,\n",
       "  'давайте': 1,\n",
       "  'расскажу': 1,\n",
       "  'более': 1,\n",
       "  'конкретно,': 1,\n",
       "  'с': 1,\n",
       "  'числами': 1,\n",
       "  'и': 1,\n",
       "  'примерами.': 1},\n",
       " 'sent1': {'Более': 1,\n",
       "  'того,': 1,\n",
       "  'они': 1,\n",
       "  'справились': 1,\n",
       "  'лучше,': 1,\n",
       "  'чем': 1,\n",
       "  'мы': 1,\n",
       "  'ждали.': 1},\n",
       " 'sent2': {'Тут': 1,\n",
       "  'наработки': 1,\n",
       "  'беспилотного': 1,\n",
       "  'трамвая': 1,\n",
       "  'после': 1,\n",
       "  'езды': 1,\n",
       "  'вокруг': 1,\n",
       "  'ВДНХ': 1,\n",
       "  'очень': 1,\n",
       "  'пригодились.': 1},\n",
       " 'sent3': {'Отдельное': 1,\n",
       "  'подразделение': 1,\n",
       "  'занимается': 1,\n",
       "  'обучением': 1,\n",
       "  'нейросетей': 1,\n",
       "  '(фотографированием': 1,\n",
       "  'ситуаций': 1,\n",
       "  'и': 1,\n",
       "  'разметкой': 1,\n",
       "  'данных),': 1,\n",
       "  'чтобы': 1,\n",
       "  'определять,': 1,\n",
       "  'где': 1,\n",
       "  'какая': 1,\n",
       "  'культура,': 1,\n",
       "  'как': 1,\n",
       "  'выглядит': 1,\n",
       "  'полёгшая': 1,\n",
       "  'пшеница': 1,\n",
       "  'так': 1,\n",
       "  'далее.': 1}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(corpus).fillna(0).astype(int).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Но</th>\n",
       "      <th>давайте</th>\n",
       "      <th>расскажу</th>\n",
       "      <th>более</th>\n",
       "      <th>конкретно,</th>\n",
       "      <th>с</th>\n",
       "      <th>числами</th>\n",
       "      <th>и</th>\n",
       "      <th>примерами.</th>\n",
       "      <th>Более</th>\n",
       "      <th>того,</th>\n",
       "      <th>они</th>\n",
       "      <th>справились</th>\n",
       "      <th>лучше,</th>\n",
       "      <th>чем</th>\n",
       "      <th>мы</th>\n",
       "      <th>ждали.</th>\n",
       "      <th>Тут</th>\n",
       "      <th>наработки</th>\n",
       "      <th>беспилотного</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Но  давайте  расскажу  более  конкретно,  с  числами  и  примерами.  \\\n",
       "sent0   1        1         1      1           1  1        1  1           1   \n",
       "sent1   0        0         0      0           0  0        0  0           0   \n",
       "sent2   0        0         0      0           0  0        0  0           0   \n",
       "sent3   0        0         0      0           0  0        0  1           0   \n",
       "\n",
       "       Более  того,  они  справились  лучше,  чем  мы  ждали.  Тут  наработки  \\\n",
       "sent0      0      0    0           0       0    0   0       0    0          0   \n",
       "sent1      1      1    1           1       1    1   1       1    0          0   \n",
       "sent2      0      0    0           0       0    0   0       0    1          1   \n",
       "sent3      0      0    0           0       0    0   0       0    0          0   \n",
       "\n",
       "       беспилотного  \n",
       "sent0             0  \n",
       "sent1             0  \n",
       "sent2             1  \n",
       "sent3             0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([1, 2, 3])\n",
    "v2 = np.array([2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sent0.dot(df.sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sent0.dot(df.sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sent0.dot(df.sent3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Но',\n",
       " 'давайте',\n",
       " 'расскажу',\n",
       " 'более',\n",
       " 'конкретно',\n",
       " 'с',\n",
       " 'числами',\n",
       " 'и',\n",
       " 'примерами',\n",
       " 'Более',\n",
       " 'того',\n",
       " 'они',\n",
       " 'справились',\n",
       " 'лучше',\n",
       " 'чем',\n",
       " 'мы',\n",
       " 'ждали',\n",
       " 'Тут',\n",
       " 'наработки',\n",
       " 'беспилотного',\n",
       " 'трамвая',\n",
       " 'после',\n",
       " 'езды',\n",
       " 'вокруг',\n",
       " 'ВДНХ',\n",
       " 'очень',\n",
       " 'пригодились',\n",
       " 'Отдельное',\n",
       " 'подразделение',\n",
       " 'занимается',\n",
       " 'обучением',\n",
       " 'нейросетей',\n",
       " '(фотографированием',\n",
       " 'ситуаций',\n",
       " 'и',\n",
       " 'разметкой',\n",
       " 'данных)',\n",
       " 'чтобы',\n",
       " 'определять',\n",
       " 'где',\n",
       " 'какая',\n",
       " 'культура',\n",
       " 'как',\n",
       " 'выглядит',\n",
       " 'полёгшая',\n",
       " 'пшеница',\n",
       " 'и',\n",
       " 'так',\n",
       " 'далее',\n",
       " '']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = re.split(r'[-\\s.,:!?]+', sentences)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Но',\n",
       " 'давайте',\n",
       " 'расскажу',\n",
       " 'более',\n",
       " 'конкретно',\n",
       " 'с',\n",
       " 'числами',\n",
       " 'и',\n",
       " 'примерами',\n",
       " 'Более',\n",
       " 'того',\n",
       " 'они',\n",
       " 'справились',\n",
       " 'лучше',\n",
       " 'чем',\n",
       " 'мы',\n",
       " 'ждали',\n",
       " 'Тут',\n",
       " 'наработки',\n",
       " 'беспилотного',\n",
       " 'трамвая',\n",
       " 'после',\n",
       " 'езды',\n",
       " 'вокруг',\n",
       " 'ВДНХ',\n",
       " 'очень',\n",
       " 'пригодились',\n",
       " 'Отдельное',\n",
       " 'подразделение',\n",
       " 'занимается',\n",
       " 'обучением',\n",
       " 'нейросетей',\n",
       " '(фотографированием',\n",
       " 'ситуаций',\n",
       " 'и',\n",
       " 'разметкой',\n",
       " 'данных)',\n",
       " 'чтобы',\n",
       " 'определять',\n",
       " 'где',\n",
       " 'какая',\n",
       " 'культура',\n",
       " 'как',\n",
       " 'выглядит',\n",
       " 'полёгшая',\n",
       " 'пшеница',\n",
       " 'и',\n",
       " 'так',\n",
       " 'далее']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = list(filter(lambda x: x if x and x not in '-\\t\\n.,;!?' else None, tokens))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Но',\n",
       " 'давайте',\n",
       " 'расскажу',\n",
       " 'более',\n",
       " 'конкретно',\n",
       " ',',\n",
       " 'с',\n",
       " 'числами',\n",
       " 'и',\n",
       " 'примерами',\n",
       " '.',\n",
       " 'Более',\n",
       " 'того',\n",
       " ',',\n",
       " 'они',\n",
       " 'справились',\n",
       " 'лучше',\n",
       " ',',\n",
       " 'чем',\n",
       " 'мы',\n",
       " 'ждали',\n",
       " '.',\n",
       " 'Тут',\n",
       " 'наработки',\n",
       " 'беспилотного',\n",
       " 'трамвая',\n",
       " 'после',\n",
       " 'езды',\n",
       " 'вокруг',\n",
       " 'ВДНХ',\n",
       " 'очень',\n",
       " 'пригодились',\n",
       " '.',\n",
       " 'Отдельное',\n",
       " 'подразделение',\n",
       " 'занимается',\n",
       " 'обучением',\n",
       " 'нейросетей',\n",
       " '(фотографированием',\n",
       " 'ситуаций',\n",
       " 'и',\n",
       " 'разметкой',\n",
       " 'данных',\n",
       " '),',\n",
       " 'чтобы',\n",
       " 'определять',\n",
       " ',',\n",
       " 'где',\n",
       " 'какая',\n",
       " 'культура',\n",
       " ',',\n",
       " 'как',\n",
       " 'выглядит',\n",
       " 'полёгшая',\n",
       " 'пшеница',\n",
       " 'и',\n",
       " 'так',\n",
       " 'далее',\n",
       " '.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+|$[0-9.]+|\\S+')\n",
    "tokenizer.tokenize(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from razdel import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Но'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = list(tokenize(sentences))\n",
    "tokens[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Но',\n",
       " 'давайте',\n",
       " 'расскажу',\n",
       " 'более',\n",
       " 'конкретно',\n",
       " 'с',\n",
       " 'числами',\n",
       " 'и',\n",
       " 'примерами',\n",
       " 'Более',\n",
       " 'того',\n",
       " 'они',\n",
       " 'справились',\n",
       " 'лучше',\n",
       " 'чем',\n",
       " 'мы',\n",
       " 'ждали',\n",
       " 'Тут',\n",
       " 'наработки',\n",
       " 'беспилотного',\n",
       " 'трамвая',\n",
       " 'после',\n",
       " 'езды',\n",
       " 'вокруг',\n",
       " 'ВДНХ',\n",
       " 'очень',\n",
       " 'пригодились',\n",
       " 'Отдельное',\n",
       " 'подразделение',\n",
       " 'занимается',\n",
       " 'обучением',\n",
       " 'нейросетей',\n",
       " 'фотографированием',\n",
       " 'ситуаций',\n",
       " 'и',\n",
       " 'разметкой',\n",
       " 'данных',\n",
       " 'чтобы',\n",
       " 'определять',\n",
       " 'где',\n",
       " 'какая',\n",
       " 'культура',\n",
       " 'как',\n",
       " 'выглядит',\n",
       " 'полёгшая',\n",
       " 'пшеница',\n",
       " 'и',\n",
       " 'так',\n",
       " 'далее']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [token.text for token in tokenize(sentences) if token.text not in '-\\t\\n.,;!?()']\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.casual import casual_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"\"\"RT @TJMonticello Best day everrrrrr at Monticello. Awesommmmeeeee day :*)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT',\n",
       " '@TJMonticello',\n",
       " 'Best',\n",
       " 'day',\n",
       " 'everrrrrr',\n",
       " 'at',\n",
       " 'Monticello',\n",
       " '.',\n",
       " 'Awesommmmeeeee',\n",
       " 'day',\n",
       " ':*)']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casual_tokenize(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT',\n",
       " 'Best',\n",
       " 'day',\n",
       " 'everrr',\n",
       " 'at',\n",
       " 'Monticello',\n",
       " '.',\n",
       " 'Awesommmeee',\n",
       " 'day',\n",
       " ':*)']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casual_tokenize(message, reduce_len=True, strip_handles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Но давайте расскажу более конкретно, с числами и примерами.\\nБолее того, они справились лучше, чем мы ждали.\\nТут наработки беспилотного трамвая после езды вокруг ВДНХ очень пригодились.\\nОтдельное подразделение занимается обучением нейросетей (фотографированием ситуаций и разметкой данных), чтобы определять, где какая культура, как выглядит полёгшая пшеница и так далее.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Но', 'давайте', 'расскажу'),\n",
       " ('давайте', 'расскажу', 'более'),\n",
       " ('расскажу', 'более', 'конкретно'),\n",
       " ('более', 'конкретно', 'с'),\n",
       " ('конкретно', 'с', 'числами'),\n",
       " ('с', 'числами', 'и'),\n",
       " ('числами', 'и', 'примерами'),\n",
       " ('и', 'примерами', 'Более'),\n",
       " ('примерами', 'Более', 'того'),\n",
       " ('Более', 'того', 'они'),\n",
       " ('того', 'они', 'справились'),\n",
       " ('они', 'справились', 'лучше'),\n",
       " ('справились', 'лучше', 'чем'),\n",
       " ('лучше', 'чем', 'мы'),\n",
       " ('чем', 'мы', 'ждали'),\n",
       " ('мы', 'ждали', 'Тут'),\n",
       " ('ждали', 'Тут', 'наработки'),\n",
       " ('Тут', 'наработки', 'беспилотного'),\n",
       " ('наработки', 'беспилотного', 'трамвая'),\n",
       " ('беспилотного', 'трамвая', 'после'),\n",
       " ('трамвая', 'после', 'езды'),\n",
       " ('после', 'езды', 'вокруг'),\n",
       " ('езды', 'вокруг', 'ВДНХ'),\n",
       " ('вокруг', 'ВДНХ', 'очень'),\n",
       " ('ВДНХ', 'очень', 'пригодились'),\n",
       " ('очень', 'пригодились', 'Отдельное'),\n",
       " ('пригодились', 'Отдельное', 'подразделение'),\n",
       " ('Отдельное', 'подразделение', 'занимается'),\n",
       " ('подразделение', 'занимается', 'обучением'),\n",
       " ('занимается', 'обучением', 'нейросетей'),\n",
       " ('обучением', 'нейросетей', 'фотографированием'),\n",
       " ('нейросетей', 'фотографированием', 'ситуаций'),\n",
       " ('фотографированием', 'ситуаций', 'и'),\n",
       " ('ситуаций', 'и', 'разметкой'),\n",
       " ('и', 'разметкой', 'данных'),\n",
       " ('разметкой', 'данных', 'чтобы'),\n",
       " ('данных', 'чтобы', 'определять'),\n",
       " ('чтобы', 'определять', 'где'),\n",
       " ('определять', 'где', 'какая'),\n",
       " ('где', 'какая', 'культура'),\n",
       " ('какая', 'культура', 'как'),\n",
       " ('культура', 'как', 'выглядит'),\n",
       " ('как', 'выглядит', 'полёгшая'),\n",
       " ('выглядит', 'полёгшая', 'пшеница'),\n",
       " ('полёгшая', 'пшеница', 'и'),\n",
       " ('пшеница', 'и', 'так'),\n",
       " ('и', 'так', 'далее')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(tokens, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kofff\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'better'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('better')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('better', pos='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$:': -1.5,\n",
       " '%)': -0.4,\n",
       " '%-)': -1.5,\n",
       " '&-:': -0.4,\n",
       " '&:': -0.7,\n",
       " \"( '}{' )\": 1.6,\n",
       " '(%': -0.9,\n",
       " \"('-:\": 2.2,\n",
       " \"(':\": 2.3,\n",
       " '((-:': 2.1,\n",
       " '(*': 1.1,\n",
       " '(-%': -0.7,\n",
       " '(-*': 1.3,\n",
       " '(-:': 1.6,\n",
       " '(-:0': 2.8,\n",
       " '(-:<': -0.4,\n",
       " '(-:o': 1.5,\n",
       " '(-:O': 1.5,\n",
       " '(-:{': -0.1,\n",
       " '(-:|>*': 1.9,\n",
       " '(-;': 1.3,\n",
       " '(-;|': 2.1,\n",
       " '(8': 2.6,\n",
       " '(:': 2.2,\n",
       " '(:0': 2.4,\n",
       " '(:<': -0.2,\n",
       " '(:o': 2.5,\n",
       " '(:O': 2.5,\n",
       " '(;': 1.1,\n",
       " '(;<': 0.3,\n",
       " '(=': 2.2,\n",
       " '(?:': 2.1,\n",
       " '(^:': 1.5,\n",
       " '(^;': 1.5,\n",
       " '(^;0': 2.0,\n",
       " '(^;o': 1.9,\n",
       " '(o:': 1.6,\n",
       " \")':\": -2.0,\n",
       " \")-':\": -2.1,\n",
       " ')-:': -2.1,\n",
       " ')-:<': -2.2,\n",
       " ')-:{': -2.1,\n",
       " '):': -1.8,\n",
       " '):<': -1.9,\n",
       " '):{': -2.3,\n",
       " ');<': -2.6,\n",
       " '*)': 0.6,\n",
       " '*-)': 0.3,\n",
       " '*-:': 2.1,\n",
       " '*-;': 2.4,\n",
       " '*:': 1.9,\n",
       " '*<|:-)': 1.6,\n",
       " '*\\\\0/*': 2.3,\n",
       " '*^:': 1.6,\n",
       " ',-:': 1.2,\n",
       " \"---'-;-{@\": 2.3,\n",
       " '--<--<@': 2.2,\n",
       " '.-:': -1.2,\n",
       " '..###-:': -1.7,\n",
       " '..###:': -1.9,\n",
       " '/-:': -1.3,\n",
       " '/:': -1.3,\n",
       " '/:<': -1.4,\n",
       " '/=': -0.9,\n",
       " '/^:': -1.0,\n",
       " '/o:': -1.4,\n",
       " '0-8': 0.1,\n",
       " '0-|': -1.2,\n",
       " '0:)': 1.9,\n",
       " '0:-)': 1.4,\n",
       " '0:-3': 1.5,\n",
       " '0:03': 1.9,\n",
       " '0;^)': 1.6,\n",
       " '0_o': -0.3,\n",
       " '10q': 2.1,\n",
       " '1337': 2.1,\n",
       " '143': 3.2,\n",
       " '1432': 2.6,\n",
       " '14aa41': 2.4,\n",
       " '182': -2.9,\n",
       " '187': -3.1,\n",
       " '2g2b4g': 2.8,\n",
       " '2g2bt': -0.1,\n",
       " '2qt': 2.1,\n",
       " '3:(': -2.2,\n",
       " '3:)': 0.5,\n",
       " '3:-(': -2.3,\n",
       " '3:-)': -1.4,\n",
       " '4col': -2.2,\n",
       " '4q': -3.1,\n",
       " '5fs': 1.5,\n",
       " '8)': 1.9,\n",
       " '8-d': 1.7,\n",
       " '8-o': -0.3,\n",
       " '86': -1.6,\n",
       " '8d': 2.9,\n",
       " ':###..': -2.4,\n",
       " ':$': -0.2,\n",
       " ':&': -0.6,\n",
       " \":'(\": -2.2,\n",
       " \":')\": 2.3,\n",
       " \":'-(\": -2.4,\n",
       " \":'-)\": 2.7,\n",
       " ':(': -1.9,\n",
       " ':)': 2.0,\n",
       " ':*': 2.5,\n",
       " ':-###..': -2.5,\n",
       " ':-&': -0.5,\n",
       " ':-(': -1.5,\n",
       " ':-)': 1.3,\n",
       " ':-))': 2.8,\n",
       " ':-*': 1.7,\n",
       " ':-,': 1.1,\n",
       " ':-.': -0.9,\n",
       " ':-/': -1.2,\n",
       " ':-<': -1.5,\n",
       " ':-d': 2.3,\n",
       " ':-D': 2.3,\n",
       " ':-o': 0.1,\n",
       " ':-p': 1.5,\n",
       " ':-[': -1.6,\n",
       " ':-\\\\': -0.9,\n",
       " ':-c': -1.3,\n",
       " ':-|': -0.7,\n",
       " ':-||': -2.5,\n",
       " ':-Þ': 0.9,\n",
       " ':/': -1.4,\n",
       " ':3': 2.3,\n",
       " ':<': -2.1,\n",
       " ':>': 2.1,\n",
       " ':?)': 1.3,\n",
       " ':?c': -1.6,\n",
       " ':@': -2.5,\n",
       " ':d': 2.3,\n",
       " ':D': 2.3,\n",
       " ':l': -1.7,\n",
       " ':o': -0.4,\n",
       " ':p': 1.0,\n",
       " ':s': -1.2,\n",
       " ':[': -2.0,\n",
       " ':\\\\': -1.3,\n",
       " ':]': 2.2,\n",
       " ':^)': 2.1,\n",
       " ':^*': 2.6,\n",
       " ':^/': -1.2,\n",
       " ':^\\\\': -1.0,\n",
       " ':^|': -1.0,\n",
       " ':c': -2.1,\n",
       " ':c)': 2.0,\n",
       " ':o)': 2.1,\n",
       " ':o/': -1.4,\n",
       " ':o\\\\': -1.1,\n",
       " ':o|': -0.6,\n",
       " ':P': 1.4,\n",
       " ':{': -1.9,\n",
       " ':|': -0.4,\n",
       " ':}': 2.1,\n",
       " ':Þ': 1.1,\n",
       " ';)': 0.9,\n",
       " ';-)': 1.0,\n",
       " ';-*': 2.2,\n",
       " ';-]': 0.7,\n",
       " ';d': 0.8,\n",
       " ';D': 0.8,\n",
       " ';]': 0.6,\n",
       " ';^)': 1.4,\n",
       " '</3': -3.0,\n",
       " '<3': 1.9,\n",
       " '<:': 2.1,\n",
       " '<:-|': -1.4,\n",
       " '=)': 2.2,\n",
       " '=-3': 2.0,\n",
       " '=-d': 2.4,\n",
       " '=-D': 2.4,\n",
       " '=/': -1.4,\n",
       " '=3': 2.1,\n",
       " '=d': 2.3,\n",
       " '=D': 2.3,\n",
       " '=l': -1.2,\n",
       " '=\\\\': -1.2,\n",
       " '=]': 1.6,\n",
       " '=p': 1.3,\n",
       " '=|': -0.8,\n",
       " '>-:': -2.0,\n",
       " '>.<': -1.3,\n",
       " '>:': -2.1,\n",
       " '>:(': -2.7,\n",
       " '>:)': 0.4,\n",
       " '>:-(': -2.7,\n",
       " '>:-)': -0.4,\n",
       " '>:/': -1.6,\n",
       " '>:o': -1.2,\n",
       " '>:p': 1.0,\n",
       " '>:[': -2.1,\n",
       " '>:\\\\': -1.7,\n",
       " '>;(': -2.9,\n",
       " '>;)': 0.1,\n",
       " '>_>^': 2.1,\n",
       " '@:': -2.1,\n",
       " '@>-->--': 2.1,\n",
       " \"@}-;-'---\": 2.2,\n",
       " 'aas': 2.5,\n",
       " 'aayf': 2.7,\n",
       " 'afu': -2.9,\n",
       " 'alol': 2.8,\n",
       " 'ambw': 2.9,\n",
       " 'aml': 3.4,\n",
       " 'atab': -1.9,\n",
       " 'awol': -1.3,\n",
       " 'ayc': 0.2,\n",
       " 'ayor': -1.2,\n",
       " 'aug-00': 0.3,\n",
       " 'bfd': -2.7,\n",
       " 'bfe': -2.6,\n",
       " 'bff': 2.9,\n",
       " 'bffn': 1.0,\n",
       " 'bl': 2.3,\n",
       " 'bsod': -2.2,\n",
       " 'btd': -2.1,\n",
       " 'btdt': -0.1,\n",
       " 'bz': 0.4,\n",
       " 'b^d': 2.6,\n",
       " 'cwot': -2.3,\n",
       " \"d-':\": -2.5,\n",
       " 'd8': -3.2,\n",
       " 'd:': 1.2,\n",
       " 'd:<': -3.2,\n",
       " 'd;': -2.9,\n",
       " 'd=': 1.5,\n",
       " 'doa': -2.3,\n",
       " 'dx': -3.0,\n",
       " 'ez': 1.5,\n",
       " 'fav': 2.0,\n",
       " 'fcol': -1.8,\n",
       " 'ff': 1.8,\n",
       " 'ffs': -2.8,\n",
       " 'fkm': -2.4,\n",
       " 'foaf': 1.8,\n",
       " 'ftw': 2.0,\n",
       " 'fu': -3.7,\n",
       " 'fubar': -3.0,\n",
       " 'fwb': 2.5,\n",
       " 'fyi': 0.8,\n",
       " 'fysa': 0.4,\n",
       " 'g1': 1.4,\n",
       " 'gg': 1.2,\n",
       " 'gga': 1.7,\n",
       " 'gigo': -0.6,\n",
       " 'gj': 2.0,\n",
       " 'gl': 1.3,\n",
       " 'gla': 2.5,\n",
       " 'gn': 1.2,\n",
       " 'gr8': 2.7,\n",
       " 'grrr': -0.4,\n",
       " 'gt': 1.1,\n",
       " 'h&k': 2.3,\n",
       " 'hagd': 2.2,\n",
       " 'hagn': 2.2,\n",
       " 'hago': 1.2,\n",
       " 'hak': 1.9,\n",
       " 'hand': 2.2,\n",
       " 'heart': 3.2,\n",
       " 'hearts': 3.3,\n",
       " 'hho1/2k': 1.4,\n",
       " 'hhoj': 2.0,\n",
       " 'hhok': 0.9,\n",
       " 'hugz': 2.0,\n",
       " 'hi5': 1.9,\n",
       " 'idk': -0.4,\n",
       " 'ijs': 0.7,\n",
       " 'ilu': 3.4,\n",
       " 'iluaaf': 2.7,\n",
       " 'ily': 3.4,\n",
       " 'ily2': 2.6,\n",
       " 'iou': 0.7,\n",
       " 'iyq': 2.3,\n",
       " 'j/j': 2.0,\n",
       " 'j/k': 1.6,\n",
       " 'j/p': 1.4,\n",
       " 'j/t': -0.2,\n",
       " 'j/w': 1.0,\n",
       " 'j4f': 1.4,\n",
       " 'j4g': 1.7,\n",
       " 'jho': 0.8,\n",
       " 'jhomf': 1.0,\n",
       " 'jj': 1.0,\n",
       " 'jk': 0.9,\n",
       " 'jp': 0.8,\n",
       " 'jt': 0.9,\n",
       " 'jw': 1.6,\n",
       " 'jealz': -1.2,\n",
       " 'k4y': 2.3,\n",
       " 'kfy': 2.3,\n",
       " 'kia': -3.2,\n",
       " 'kk': 1.5,\n",
       " 'kmuf': 2.2,\n",
       " 'l': 2.0,\n",
       " 'l&r': 2.2,\n",
       " 'laoj': 1.3,\n",
       " 'lmao': 2.9,\n",
       " 'lmbao': 1.8,\n",
       " 'lmfao': 2.5,\n",
       " 'lmso': 2.7,\n",
       " 'lol': 1.8,\n",
       " 'lolz': 2.7,\n",
       " 'lts': 1.6,\n",
       " 'ly': 2.6,\n",
       " 'ly4e': 2.7,\n",
       " 'lya': 3.3,\n",
       " 'lyb': 3.0,\n",
       " 'lyl': 3.1,\n",
       " 'lylab': 2.7,\n",
       " 'lylas': 2.6,\n",
       " 'lylb': 1.6,\n",
       " 'm8': 1.4,\n",
       " 'mia': -1.2,\n",
       " 'mml': 2.0,\n",
       " 'mofo': -2.4,\n",
       " 'muah': 2.3,\n",
       " 'mubar': -1.0,\n",
       " 'musm': 0.9,\n",
       " 'mwah': 2.5,\n",
       " 'n1': 1.9,\n",
       " 'nbd': 1.3,\n",
       " 'nbif': -0.5,\n",
       " 'nfc': -2.7,\n",
       " 'nfw': -2.4,\n",
       " 'nh': 2.2,\n",
       " 'nimby': -0.8,\n",
       " 'nimjd': -0.7,\n",
       " 'nimq': -0.2,\n",
       " 'nimy': -1.4,\n",
       " 'nitl': -1.5,\n",
       " 'nme': -2.1,\n",
       " 'noyb': -0.7,\n",
       " 'np': 1.4,\n",
       " 'ntmu': 1.4,\n",
       " 'o-8': -0.5,\n",
       " 'o-:': -0.3,\n",
       " 'o-|': -1.1,\n",
       " 'o.o': -0.8,\n",
       " 'O.o': -0.6,\n",
       " 'o.O': -0.6,\n",
       " 'o:': -0.2,\n",
       " 'o:)': 1.5,\n",
       " 'o:-)': 2.0,\n",
       " 'o:-3': 2.2,\n",
       " 'o:3': 2.3,\n",
       " 'o:<': -0.3,\n",
       " 'o;^)': 1.6,\n",
       " 'ok': 1.2,\n",
       " 'o_o': -0.5,\n",
       " 'O_o': -0.5,\n",
       " 'o_O': -0.5,\n",
       " 'pita': -2.4,\n",
       " 'pls': 0.3,\n",
       " 'plz': 0.3,\n",
       " 'pmbi': 0.8,\n",
       " 'pmfji': 0.3,\n",
       " 'pmji': 0.7,\n",
       " 'po': -2.6,\n",
       " 'ptl': 2.6,\n",
       " 'pu': -1.1,\n",
       " 'qq': -2.2,\n",
       " 'qt': 1.8,\n",
       " 'r&r': 2.4,\n",
       " 'rofl': 2.7,\n",
       " 'roflmao': 2.5,\n",
       " 'rotfl': 2.6,\n",
       " 'rotflmao': 2.8,\n",
       " 'rotflmfao': 2.5,\n",
       " 'rotflol': 3.0,\n",
       " 'rotgl': 2.9,\n",
       " 'rotglmao': 1.8,\n",
       " 's:': -1.1,\n",
       " 'sapfu': -1.1,\n",
       " 'sete': 2.8,\n",
       " 'sfete': 2.7,\n",
       " 'sgtm': 2.4,\n",
       " 'slap': 0.6,\n",
       " 'slaw': 2.1,\n",
       " 'smh': -1.3,\n",
       " 'snafu': -2.5,\n",
       " 'sob': -1.0,\n",
       " 'swak': 2.3,\n",
       " 'tgif': 2.3,\n",
       " 'thks': 1.4,\n",
       " 'thx': 1.5,\n",
       " 'tia': 2.3,\n",
       " 'tmi': -0.3,\n",
       " 'tnx': 1.1,\n",
       " 'true': 1.8,\n",
       " 'tx': 1.5,\n",
       " 'txs': 1.1,\n",
       " 'ty': 1.6,\n",
       " 'tyvm': 2.5,\n",
       " 'urw': 1.9,\n",
       " 'vbg': 2.1,\n",
       " 'vbs': 3.1,\n",
       " 'vip': 2.3,\n",
       " 'vwd': 2.6,\n",
       " 'vwp': 2.1,\n",
       " 'wag': -0.2,\n",
       " 'wd': 2.7,\n",
       " 'wilco': 0.9,\n",
       " 'wp': 1.0,\n",
       " 'wtf': -2.8,\n",
       " 'wtg': 2.1,\n",
       " 'wth': -2.4,\n",
       " 'x-d': 2.6,\n",
       " 'x-p': 1.7,\n",
       " 'xd': 2.8,\n",
       " 'xlnt': 3.0,\n",
       " 'xoxo': 3.0,\n",
       " 'xoxozzz': 2.3,\n",
       " 'xp': 1.6,\n",
       " 'xqzt': 1.6,\n",
       " 'xtc': 0.8,\n",
       " 'yolo': 1.1,\n",
       " 'yoyo': 0.4,\n",
       " 'yvw': 1.6,\n",
       " 'yw': 1.8,\n",
       " 'ywia': 2.5,\n",
       " 'zzz': -1.2,\n",
       " '[-;': 0.5,\n",
       " '[:': 1.3,\n",
       " '[;': 1.0,\n",
       " '[=': 1.7,\n",
       " '\\\\-:': -1.0,\n",
       " '\\\\:': -1.0,\n",
       " '\\\\:<': -1.7,\n",
       " '\\\\=': -1.1,\n",
       " '\\\\^:': -1.3,\n",
       " '\\\\o/': 2.2,\n",
       " '\\\\o:': -1.2,\n",
       " ']-:': -2.1,\n",
       " ']:': -1.6,\n",
       " ']:<': -2.5,\n",
       " '^<_<': 1.4,\n",
       " '^urs': -2.8,\n",
       " 'abandon': -1.9,\n",
       " 'abandoned': -2.0,\n",
       " 'abandoner': -1.9,\n",
       " 'abandoners': -1.9,\n",
       " 'abandoning': -1.6,\n",
       " 'abandonment': -2.4,\n",
       " 'abandonments': -1.7,\n",
       " 'abandons': -1.3,\n",
       " 'abducted': -2.3,\n",
       " 'abduction': -2.8,\n",
       " 'abductions': -2.0,\n",
       " 'abhor': -2.0,\n",
       " 'abhorred': -2.4,\n",
       " 'abhorrent': -3.1,\n",
       " 'abhors': -2.9,\n",
       " 'abilities': 1.0,\n",
       " 'ability': 1.3,\n",
       " 'aboard': 0.1,\n",
       " 'absentee': -1.1,\n",
       " 'absentees': -0.8,\n",
       " 'absolve': 1.2,\n",
       " 'absolved': 1.5,\n",
       " 'absolves': 1.3,\n",
       " 'absolving': 1.6,\n",
       " 'abuse': -3.2,\n",
       " 'abused': -2.3,\n",
       " 'abuser': -2.6,\n",
       " 'abusers': -2.6,\n",
       " 'abuses': -2.6,\n",
       " 'abusing': -2.0,\n",
       " 'abusive': -3.2,\n",
       " 'abusively': -2.8,\n",
       " 'abusiveness': -2.5,\n",
       " 'abusivenesses': -3.0,\n",
       " 'accept': 1.6,\n",
       " 'acceptabilities': 1.6,\n",
       " 'acceptability': 1.1,\n",
       " 'acceptable': 1.3,\n",
       " 'acceptableness': 1.3,\n",
       " 'acceptably': 1.5,\n",
       " 'acceptance': 2.0,\n",
       " 'acceptances': 1.7,\n",
       " 'acceptant': 1.6,\n",
       " 'acceptation': 1.3,\n",
       " 'acceptations': 0.9,\n",
       " 'accepted': 1.1,\n",
       " 'accepting': 1.6,\n",
       " 'accepts': 1.3,\n",
       " 'accident': -2.1,\n",
       " 'accidental': -0.3,\n",
       " 'accidentally': -1.4,\n",
       " 'accidents': -1.3,\n",
       " 'accomplish': 1.8,\n",
       " 'accomplished': 1.9,\n",
       " 'accomplishes': 1.7,\n",
       " 'accusation': -1.0,\n",
       " 'accusations': -1.3,\n",
       " 'accuse': -0.8,\n",
       " 'accused': -1.2,\n",
       " 'accuses': -1.4,\n",
       " 'accusing': -0.7,\n",
       " 'ache': -1.6,\n",
       " 'ached': -1.6,\n",
       " 'aches': -1.0,\n",
       " 'achievable': 1.3,\n",
       " 'aching': -2.2,\n",
       " 'acquit': 0.8,\n",
       " 'acquits': 0.1,\n",
       " 'acquitted': 1.0,\n",
       " 'acquitting': 1.3,\n",
       " 'acrimonious': -1.7,\n",
       " 'active': 1.7,\n",
       " 'actively': 1.3,\n",
       " 'activeness': 0.6,\n",
       " 'activenesses': 0.8,\n",
       " 'actives': 1.1,\n",
       " 'adequate': 0.9,\n",
       " 'admirability': 2.4,\n",
       " 'admirable': 2.6,\n",
       " 'admirableness': 2.2,\n",
       " 'admirably': 2.5,\n",
       " 'admiral': 1.3,\n",
       " 'admirals': 1.5,\n",
       " 'admiralties': 1.6,\n",
       " 'admiralty': 1.2,\n",
       " 'admiration': 2.5,\n",
       " 'admirations': 1.6,\n",
       " 'admire': 2.1,\n",
       " 'admired': 2.3,\n",
       " 'admirer': 1.8,\n",
       " 'admirers': 1.7,\n",
       " 'admires': 1.5,\n",
       " 'admiring': 1.6,\n",
       " 'admiringly': 2.3,\n",
       " 'admit': 0.8,\n",
       " 'admits': 1.2,\n",
       " 'admitted': 0.4,\n",
       " 'admonished': -1.9,\n",
       " 'adopt': 0.7,\n",
       " 'adopts': 0.7,\n",
       " 'adorability': 2.2,\n",
       " 'adorable': 2.2,\n",
       " 'adorableness': 2.5,\n",
       " 'adorably': 2.1,\n",
       " 'adoration': 2.9,\n",
       " 'adorations': 2.2,\n",
       " 'adore': 2.6,\n",
       " 'adored': 1.8,\n",
       " 'adorer': 1.7,\n",
       " 'adorers': 2.1,\n",
       " 'adores': 1.6,\n",
       " 'adoring': 2.6,\n",
       " 'adoringly': 2.4,\n",
       " 'adorn': 0.9,\n",
       " 'adorned': 0.8,\n",
       " 'adorner': 1.3,\n",
       " 'adorners': 0.9,\n",
       " 'adorning': 1.0,\n",
       " 'adornment': 1.3,\n",
       " 'adornments': 0.8,\n",
       " 'adorns': 0.5,\n",
       " 'advanced': 1.0,\n",
       " 'advantage': 1.0,\n",
       " 'advantaged': 1.4,\n",
       " 'advantageous': 1.5,\n",
       " 'advantageously': 1.9,\n",
       " 'advantageousness': 1.6,\n",
       " 'advantages': 1.5,\n",
       " 'advantaging': 1.6,\n",
       " 'adventure': 1.3,\n",
       " 'adventured': 1.3,\n",
       " 'adventurer': 1.2,\n",
       " 'adventurers': 0.9,\n",
       " 'adventures': 1.4,\n",
       " 'adventuresome': 1.7,\n",
       " 'adventuresomeness': 1.3,\n",
       " 'adventuress': 0.8,\n",
       " 'adventuresses': 1.4,\n",
       " 'adventuring': 2.3,\n",
       " 'adventurism': 1.5,\n",
       " 'adventurist': 1.4,\n",
       " 'adventuristic': 1.7,\n",
       " 'adventurists': 1.2,\n",
       " 'adventurous': 1.4,\n",
       " 'adventurously': 1.3,\n",
       " 'adventurousness': 1.8,\n",
       " 'adversarial': -1.5,\n",
       " 'adversaries': -1.0,\n",
       " 'adversary': -0.8,\n",
       " 'adversative': -1.2,\n",
       " 'adversatively': -0.1,\n",
       " 'adversatives': -1.0,\n",
       " 'adverse': -1.5,\n",
       " 'adversely': -0.8,\n",
       " 'adverseness': -0.6,\n",
       " 'adversities': -1.5,\n",
       " 'adversity': -1.8,\n",
       " 'affected': -0.6,\n",
       " 'affection': 2.4,\n",
       " 'affectional': 1.9,\n",
       " 'affectionally': 1.5,\n",
       " 'affectionate': 1.9,\n",
       " 'affectionately': 2.2,\n",
       " 'affectioned': 1.8,\n",
       " 'affectionless': -2.0,\n",
       " 'affections': 1.5,\n",
       " 'afflicted': -1.5,\n",
       " 'affronted': 0.2,\n",
       " 'aggravate': -2.5,\n",
       " 'aggravated': -1.9,\n",
       " 'aggravates': -1.9,\n",
       " 'aggravating': -1.2,\n",
       " 'aggress': -1.3,\n",
       " 'aggressed': -1.4,\n",
       " 'aggresses': -0.5,\n",
       " 'aggressing': -0.6,\n",
       " 'aggression': -1.2,\n",
       " 'aggressions': -1.3,\n",
       " 'aggressive': -0.6,\n",
       " 'aggressively': -1.3,\n",
       " 'aggressiveness': -1.8,\n",
       " 'aggressivities': -1.4,\n",
       " 'aggressivity': -0.6,\n",
       " 'aggressor': -0.8,\n",
       " 'aggressors': -0.9,\n",
       " 'aghast': -1.9,\n",
       " 'agitate': -1.7,\n",
       " 'agitated': -2.0,\n",
       " 'agitatedly': -1.6,\n",
       " 'agitates': -1.4,\n",
       " 'agitating': -1.8,\n",
       " 'agitation': -1.0,\n",
       " 'agitational': -1.2,\n",
       " 'agitations': -1.3,\n",
       " 'agitative': -1.3,\n",
       " 'agitato': -0.1,\n",
       " 'agitator': -1.4,\n",
       " 'agitators': -2.1,\n",
       " 'agog': 1.9,\n",
       " 'agonise': -2.1,\n",
       " 'agonised': -2.3,\n",
       " 'agonises': -2.4,\n",
       " 'agonising': -1.5,\n",
       " 'agonize': -2.3,\n",
       " 'agonized': -2.2,\n",
       " 'agonizes': -2.3,\n",
       " 'agonizing': -2.7,\n",
       " 'agonizingly': -2.3,\n",
       " 'agony': -1.8,\n",
       " 'agree': 1.5,\n",
       " 'agreeability': 1.9,\n",
       " 'agreeable': 1.8,\n",
       " 'agreeableness': 1.8,\n",
       " 'agreeablenesses': 1.3,\n",
       " 'agreeably': 1.6,\n",
       " 'agreed': 1.1,\n",
       " 'agreeing': 1.4,\n",
       " 'agreement': 2.2,\n",
       " 'agreements': 1.1,\n",
       " 'agrees': 0.8,\n",
       " 'alarm': -1.4,\n",
       " 'alarmed': -1.4,\n",
       " 'alarming': -0.5,\n",
       " 'alarmingly': -2.6,\n",
       " 'alarmism': -0.3,\n",
       " 'alarmists': -1.1,\n",
       " 'alarms': -1.1,\n",
       " 'alas': -1.1,\n",
       " 'alert': 1.2,\n",
       " 'alienation': -1.1,\n",
       " 'alive': 1.6,\n",
       " 'allergic': -1.2,\n",
       " 'allow': 0.9,\n",
       " 'alone': -1.0,\n",
       " 'alright': 1.0,\n",
       " 'amaze': 2.5,\n",
       " 'amazed': 2.2,\n",
       " 'amazedly': 2.1,\n",
       " 'amazement': 2.5,\n",
       " 'amazements': 2.2,\n",
       " 'amazes': 2.2,\n",
       " 'amazing': 2.8,\n",
       " 'amazon': 0.7,\n",
       " 'amazonite': 0.2,\n",
       " 'amazons': -0.1,\n",
       " 'amazonstone': 1.0,\n",
       " 'amazonstones': 0.2,\n",
       " 'ambitious': 2.1,\n",
       " 'ambivalent': 0.5,\n",
       " 'amor': 3.0,\n",
       " 'amoral': -1.6,\n",
       " 'amoralism': -0.7,\n",
       " 'amoralisms': -0.7,\n",
       " 'amoralities': -1.2,\n",
       " 'amorality': -1.5,\n",
       " 'amorally': -1.0,\n",
       " 'amoretti': 0.2,\n",
       " 'amoretto': 0.6,\n",
       " 'amorettos': 0.3,\n",
       " 'amorino': 1.2,\n",
       " 'amorist': 1.6,\n",
       " 'amoristic': 1.0,\n",
       " 'amorists': 0.1,\n",
       " 'amoroso': 2.3,\n",
       " 'amorous': 1.8,\n",
       " 'amorously': 2.3,\n",
       " 'amorousness': 2.0,\n",
       " 'amorphous': -0.2,\n",
       " 'amorphously': 0.1,\n",
       " 'amorphousness': 0.3,\n",
       " 'amort': -2.1,\n",
       " 'amortise': 0.5,\n",
       " 'amortised': -0.2,\n",
       " 'amortises': 0.1,\n",
       " 'amortizable': 0.5,\n",
       " 'amortization': 0.6,\n",
       " 'amortizations': 0.2,\n",
       " 'amortize': -0.1,\n",
       " 'amortized': 0.8,\n",
       " 'amortizes': 0.6,\n",
       " 'amortizing': 0.8,\n",
       " 'amusable': 0.7,\n",
       " 'amuse': 1.7,\n",
       " 'amused': 1.8,\n",
       " 'amusedly': 2.2,\n",
       " 'amusement': 1.5,\n",
       " 'amusements': 1.5,\n",
       " 'amuser': 1.1,\n",
       " 'amusers': 1.3,\n",
       " 'amuses': 1.7,\n",
       " 'amusia': 0.3,\n",
       " 'amusias': -0.4,\n",
       " 'amusing': 1.6,\n",
       " 'amusingly': 0.8,\n",
       " 'amusingness': 1.8,\n",
       " 'amusive': 1.7,\n",
       " 'anger': -2.7,\n",
       " 'angered': -2.3,\n",
       " 'angering': -2.2,\n",
       " 'angerly': -1.9,\n",
       " 'angers': -2.3,\n",
       " 'angrier': -2.3,\n",
       " 'angriest': -3.1,\n",
       " 'angrily': -1.8,\n",
       " 'angriness': -1.7,\n",
       " 'angry': -2.3,\n",
       " 'anguish': -2.9,\n",
       " 'anguished': -1.8,\n",
       " 'anguishes': -2.1,\n",
       " 'anguishing': -2.7,\n",
       " 'animosity': -1.9,\n",
       " 'annoy': -1.9,\n",
       " 'annoyance': -1.3,\n",
       " 'annoyances': -1.8,\n",
       " 'annoyed': -1.6,\n",
       " 'annoyer': -2.2,\n",
       " 'annoyers': -1.5,\n",
       " 'annoying': -1.7,\n",
       " 'annoys': -1.8,\n",
       " 'antagonism': -1.9,\n",
       " 'antagonisms': -1.2,\n",
       " 'antagonist': -1.9,\n",
       " 'antagonistic': -1.7,\n",
       " 'antagonistically': -2.2,\n",
       " 'antagonists': -1.7,\n",
       " 'antagonize': -2.0,\n",
       " 'antagonized': -1.4,\n",
       " 'antagonizes': -0.5,\n",
       " 'antagonizing': -2.7,\n",
       " 'anti': -1.3,\n",
       " 'anticipation': 0.4,\n",
       " 'anxieties': -0.6,\n",
       " 'anxiety': -0.7,\n",
       " 'anxious': -1.0,\n",
       " 'anxiously': -0.9,\n",
       " 'anxiousness': -1.0,\n",
       " 'aok': 2.0,\n",
       " 'apathetic': -1.2,\n",
       " 'apathetically': -0.4,\n",
       " 'apathies': -0.6,\n",
       " 'apathy': -1.2,\n",
       " 'apeshit': -0.9,\n",
       " 'apocalyptic': -3.4,\n",
       " 'apologise': 1.6,\n",
       " 'apologised': 0.4,\n",
       " 'apologises': 0.8,\n",
       " 'apologising': 0.2,\n",
       " 'apologize': 0.4,\n",
       " 'apologized': 1.3,\n",
       " 'apologizes': 1.5,\n",
       " 'apologizing': -0.3,\n",
       " 'apology': 0.2,\n",
       " 'appall': -2.4,\n",
       " 'appalled': -2.0,\n",
       " 'appalling': -1.5,\n",
       " 'appallingly': -2.0,\n",
       " 'appalls': -1.9,\n",
       " 'appease': 1.1,\n",
       " 'appeased': 0.9,\n",
       " 'appeases': 0.9,\n",
       " 'appeasing': 1.0,\n",
       " 'applaud': 2.0,\n",
       " 'applauded': 1.5,\n",
       " 'applauding': 2.1,\n",
       " 'applauds': 1.4,\n",
       " 'applause': 1.8,\n",
       " 'appreciate': 1.7,\n",
       " 'appreciated': 2.3,\n",
       " 'appreciates': 2.3,\n",
       " 'appreciating': 1.9,\n",
       " 'appreciation': 2.3,\n",
       " 'appreciations': 1.7,\n",
       " 'appreciative': 2.6,\n",
       " 'appreciatively': 1.8,\n",
       " 'appreciativeness': 1.6,\n",
       " 'appreciator': 2.6,\n",
       " 'appreciators': 1.5,\n",
       " 'appreciatory': 1.7,\n",
       " 'apprehensible': 1.1,\n",
       " 'apprehensibly': -0.2,\n",
       " 'apprehension': -2.1,\n",
       " 'apprehensions': -0.9,\n",
       " 'apprehensively': -0.3,\n",
       " 'apprehensiveness': -0.7,\n",
       " 'approval': 2.1,\n",
       " 'approved': 1.8,\n",
       " 'approves': 1.7,\n",
       " 'ardent': 2.1,\n",
       " 'arguable': -1.0,\n",
       " 'arguably': -1.0,\n",
       " 'argue': -1.4,\n",
       " 'argued': -1.5,\n",
       " 'arguer': -1.6,\n",
       " 'arguers': -1.4,\n",
       " 'argues': -1.6,\n",
       " 'arguing': -2.0,\n",
       " 'argument': -1.5,\n",
       " 'argumentative': -1.5,\n",
       " 'argumentatively': -1.8,\n",
       " 'argumentive': -1.5,\n",
       " 'arguments': -1.7,\n",
       " 'arrest': -1.4,\n",
       " 'arrested': -2.1,\n",
       " 'arrests': -1.9,\n",
       " 'arrogance': -2.4,\n",
       " 'arrogances': -1.9,\n",
       " 'arrogant': -2.2,\n",
       " 'arrogantly': -1.8,\n",
       " 'ashamed': -2.1,\n",
       " 'ashamedly': -1.7,\n",
       " 'ass': -2.5,\n",
       " 'assassination': -2.9,\n",
       " 'assassinations': -2.7,\n",
       " 'assault': -2.8,\n",
       " 'assaulted': -2.4,\n",
       " 'assaulting': -2.3,\n",
       " 'assaultive': -2.8,\n",
       " 'assaults': -2.5,\n",
       " 'asset': 1.5,\n",
       " 'assets': 0.7,\n",
       " 'assfucking': -2.5,\n",
       " 'assholes': -2.8,\n",
       " 'assurance': 1.4,\n",
       " 'assurances': 1.4,\n",
       " 'assure': 1.4,\n",
       " 'assured': 1.5,\n",
       " 'assuredly': 1.6,\n",
       " 'assuredness': 1.4,\n",
       " 'assurer': 0.9,\n",
       " 'assurers': 1.1,\n",
       " 'assures': 1.3,\n",
       " 'assurgent': 1.3,\n",
       " 'assuring': 1.6,\n",
       " 'assuror': 0.5,\n",
       " 'assurors': 0.7,\n",
       " 'astonished': 1.6,\n",
       " 'astound': 1.7,\n",
       " 'astounded': 1.8,\n",
       " 'astounding': 1.8,\n",
       " 'astoundingly': 2.1,\n",
       " 'astounds': 2.1,\n",
       " 'attachment': 1.2,\n",
       " 'attachments': 1.1,\n",
       " 'attack': -2.1,\n",
       " 'attacked': -2.0,\n",
       " 'attacker': -2.7,\n",
       " 'attackers': -2.7,\n",
       " 'attacking': -2.0,\n",
       " 'attacks': -1.9,\n",
       " 'attract': 1.5,\n",
       " 'attractancy': 0.9,\n",
       " 'attractant': 1.3,\n",
       " 'attractants': 1.4,\n",
       " 'attracted': 1.8,\n",
       " 'attracting': 2.1,\n",
       " 'attraction': 2.0,\n",
       " 'attractions': 1.8,\n",
       " 'attractive': 1.9,\n",
       " 'attractively': 2.2,\n",
       " 'attractiveness': 1.8,\n",
       " 'attractivenesses': 2.1,\n",
       " 'attractor': 1.2,\n",
       " 'attractors': 1.2,\n",
       " 'attracts': 1.7,\n",
       " 'audacious': 0.9,\n",
       " 'authority': 0.3,\n",
       " 'aversion': -1.9,\n",
       " 'aversions': -1.1,\n",
       " 'aversive': -1.6,\n",
       " 'aversively': -0.8,\n",
       " 'avert': -0.7,\n",
       " 'averted': -0.3,\n",
       " 'averts': -0.4,\n",
       " 'avid': 1.2,\n",
       " 'avoid': -1.2,\n",
       " 'avoidance': -1.7,\n",
       " 'avoidances': -1.1,\n",
       " 'avoided': -1.4,\n",
       " 'avoider': -1.8,\n",
       " 'avoiders': -1.4,\n",
       " 'avoiding': -1.4,\n",
       " 'avoids': -0.7,\n",
       " 'await': 0.4,\n",
       " 'awaited': -0.1,\n",
       " 'awaits': 0.3,\n",
       " 'award': 2.5,\n",
       " 'awardable': 2.4,\n",
       " 'awarded': 1.7,\n",
       " 'awardee': 1.8,\n",
       " 'awardees': 1.2,\n",
       " 'awarder': 0.9,\n",
       " 'awarders': 1.3,\n",
       " 'awarding': 1.9,\n",
       " 'awards': 2.0,\n",
       " 'awesome': 3.1,\n",
       " 'awful': -2.0,\n",
       " 'awkward': -0.6,\n",
       " 'awkwardly': -1.3,\n",
       " 'awkwardness': -0.7,\n",
       " 'axe': -0.4,\n",
       " 'axed': -1.3,\n",
       " 'backed': 0.1,\n",
       " 'backing': 0.1,\n",
       " 'backs': -0.2,\n",
       " 'bad': -2.5,\n",
       " 'badass': 1.4,\n",
       " 'badly': -2.1,\n",
       " 'bailout': -0.4,\n",
       " 'bamboozle': -1.5,\n",
       " 'bamboozled': -1.5,\n",
       " 'bamboozles': -1.5,\n",
       " 'ban': -2.6,\n",
       " 'banish': -1.9,\n",
       " 'bankrupt': -2.6,\n",
       " 'bankster': -2.1,\n",
       " 'banned': -2.0,\n",
       " 'bargain': 0.8,\n",
       " 'barrier': -0.5,\n",
       " 'bashful': -0.1,\n",
       " 'bashfully': 0.2,\n",
       " 'bashfulness': -0.8,\n",
       " 'bastard': -2.5,\n",
       " 'bastardies': -1.8,\n",
       " 'bastardise': -2.1,\n",
       " 'bastardised': -2.3,\n",
       " 'bastardises': -2.3,\n",
       " 'bastardising': -2.6,\n",
       " 'bastardization': -2.4,\n",
       " 'bastardizations': -2.1,\n",
       " 'bastardize': -2.4,\n",
       " 'bastardized': -2.0,\n",
       " 'bastardizes': -1.8,\n",
       " 'bastardizing': -2.3,\n",
       " 'bastardly': -2.7,\n",
       " 'bastards': -3.0,\n",
       " 'bastardy': -2.7,\n",
       " 'battle': -1.6,\n",
       " 'battled': -1.2,\n",
       " 'battlefield': -1.6,\n",
       " 'battlefields': -0.9,\n",
       " 'battlefront': -1.2,\n",
       " 'battlefronts': -0.8,\n",
       " 'battleground': -1.7,\n",
       " 'battlegrounds': -0.6,\n",
       " 'battlement': -0.4,\n",
       " 'battlements': -0.4,\n",
       " 'battler': -0.8,\n",
       " 'battlers': -0.2,\n",
       " 'battles': -1.6,\n",
       " 'battleship': -0.1,\n",
       " 'battleships': -0.5,\n",
       " 'battlewagon': -0.3,\n",
       " 'battlewagons': -0.5,\n",
       " 'battling': -1.1,\n",
       " 'beaten': -1.8,\n",
       " 'beatific': 1.8,\n",
       " 'beating': -2.0,\n",
       " 'beaut': 1.6,\n",
       " 'beauteous': 2.5,\n",
       " 'beauteously': 2.6,\n",
       " ...}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sa = SentimentIntensityAnalyzer()\n",
    "sa.lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7506"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sa.lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"( '}{' )\", 1.6),\n",
       " (\"can't stand\", -2.0),\n",
       " ('fed up', -1.8),\n",
       " ('screwed up', -1.5)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(tok, score) for tok, score in sa.lexicon.items() if ' ' in tok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.661, 'pos': 0.339, 'compound': 0.6249}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.polarity_scores(text=\"Python is very readable and it's great for NLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.548, 'neu': 0.452, 'pos': 0.0, 'compound': -0.8059}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.polarity_scores(text=\"IT'S SO FUCKING UGLY, YOU ARE STUPID SUKA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
