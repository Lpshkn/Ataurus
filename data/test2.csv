text
"Все ходил-ходил, ни как не мог понять — что же оно мне напоминает…


Какой-то тайный мессэдж на уровне подсосзнания, или дизайнеры лажанулись?"
"Перед тем как мы начнём, скажу: я знаю об OpenGL гораздо больше чем о Direct3D. Я в жизни не написал ни одной строки кода для D3D, и я писал руководства по OpenGL. Так что то что я тут расскажу, не вопрос предвзятости. Теперь это просто история.


Зарождение конфликта

Однажды, в начале 90-х, Microsoft огляделась вокруг. Они увидели замечательные Super Nintendo и Sega Genesis, на которых было много отличных игр. И они увидели DOS. Разработчики писали для DOS так же как для консолей: прямо на железе. Но, в отличии от консолей, где разработчик точно знал каким железом располагает пользователь, разработчики для DOS вынуждены были писать в расчёте на множество различных конфигураций оборудования. А это гораздо сложнее, чем кажется на первый взгляд.

У Microsoft в то время была ещё большая проблема: Windows. Windows хотела единолично распоряжаться оборудованием, в отличие от DOS, позволявшей разработчику делать всё что ему заблагорассудится. Владение оборудованием было обязательно для того чтобы упорядочить взаимодействие между приложениями. Взаимодействие-то и не нравилось разработчикам игр, потому что забирало ценные ресурсы, которые они могли использовать для своих замечательных игр.

Чтобы привлечь разработчиков игр в Windows, Microsoft нужен был единый API который был бы низкоуровневым, работал в Windows и при этом не страдал от тормозов и, самое главное, абстрагировал бы от разработчика оборудование. Единый API для графики, звука и пользовательского ввода.

И так родился DirectX.

3D ускорители появились на свет несколько месяцев спустя. И перед Microsoft встало сразу несколько проблем. Видите ли, DirectDraw, графический компонент DirectX, работал только с 2D графикой: выделением графической памяти и побитовым копированием между разными выделенными секциями памяти.

И Microsoft купили некий промежуточный драйвер и сделали из него Direct3D версии 3. Его ругали все и повсюду. И не просто так; одного взгляда на код было достаточно чтобы отшатнуться в ужасе.

Старый Джон Кармак из Id Software взглянул на этот мусор, сказал: «К чёрту!», и решил писать под другой API — OpenGL.

Другая часть этого клубка проблем состояла в том что Microsoft были очень заняты совместной работой с SGI над реализацией OpenGL для Windows. Идея была проста — привлечь разработчиков типичных рабочих GL-приложений: систем автоматического проектирования, моделирования, всего такого. Игры были последним, о чём тогда думали в Microsoft. Это всё предназначалось для Windows NT, но Microsoft решили добавить эту реализацию и в Win95.

Чтобы привлечь внимание разработчиков профессионального софта к Windows, Microsoft попробовали подкупить их доступом к новым функциям ускорителей трехмерной графики. Microsoft сделали протокол Installable Client Driver: производитель графического ускорителя мог перегрузить программную реализацию OpenGL аппаратной. Код просто автоматически использовал аппаратную реализацию если она была доступна.

Восход OpenGL

Итак, расклад сил был определён: Direct3D против OpenGL. Это действительно интересная история, учитывая насколько ужасен был D3D v3.

Комитет Архитектурных Решений OpenGL («Architectural Review Board», ARB) был организацией, ответственной за поддержку стандарта OpenGL. Они выпустили много расширений, следили за репозиторием расширений и создавали новые версии API. В Комитет входили многие влиятельные игроки графической индустрии и разработчики ОС. Apple и Microsoft в своё время тоже входили в этот комитет.

Потом появился 3Dfx с Voodoo2. Это было первое устройство, способное выполнять мультитекстурирование, чего OpenGL делать раньше не мог. Хотя 3Dfx совершенно не вписывался в стандарт OpenGL, NVIDIA, разработчик последующих графических чипов с мультитекстурированием (TNT1), положили глаз на эту реализацию. ARB пришлось выпустить расширение: GL_ARB_multitexture, которое давало доступ к мультитекстурированию.

В это же время вышел Direct3D v5. Теперь D3D стал настоящим API, а не странным куском кошачьей рвоты. Проблема? Отсутствие мультитекстурирования.

Упс.

По большому счёту, это было не так важно как должно было быть, потому что люди особо не использовали мультитекстурирование. По крайней мере напрямую. Мультитекстурирование сильно ухудшало быстродействие, и во многих случаях просто не было смысла использовать его вместо multi-passing. И, естественно, разработчики игр старались убедиться что их игры заработают на старом железе, в котором мультитекстурирования не было, и многие игры его просто не использовали.

D3D это сошло с рук.

Прошло какое то время и NVIDIA выпустили GeForce 256 (не GeForce GT-250; самый первый GeForce), по большому счёту прекратив гонку вооружений в графических ускорителях на следующие два года. Основная продающая фишка — возможность делать вертексные преобразования и освещение (T&L) аппаратно. Но это не всё: NVIDIA настолько полюбили OpenGL, что их движок T&L по сути и был OpenGL. Причём буквально: насколько я понимаю, некоторые регистры действительно напрямую принимали объекты OpenGL в качестве значений.

Выходит Direct3D v6. Наконец появилось мультитекстурирование, но… нет аппаратного T&L. У OpenGL всегда был конвеер T&L, даже до того как вышел 256 он был реализован программно. Так что для NVIDIA было не очень сложно преобразовать программную реализацию в аппаратную. В D3D аппаратный T&L появился только к седьмой версии.

Рассвет шейдеров, сумерки OpenGL

Потом вышел GeForce 3 и одновременно произошло много вещей.

Microsoft решили что теперь-то они уж точно не опоздают к празднику. И вместо того чтобы смотреть что делают NVIDIA и копировать это постфактум они пришли к NVIDIA и поговорили. Потом они полюбили друг друга и от этого союза появилась маленькая игровая приставка.

Потом был болезненный развод. Но это совсем другая история. 

Для PC это значило что GeForce 3 вышел одновременно с D3D v8. И несложно увидеть насколько GeForce 3 повлиял на шейдеры в восьмерке. Пиксельные шейдеры в Shader Model 1 были очень сильно привязаны к железу NVIDIA. Аппаратной абстракции от NVIDIA не было вообше; SM 1.0 по сути был тем что делал GeForce 3.

Когда ATI вступили в гонку производительных графических карт со своим Radeon 8500, обнаружилась проблема. Пиксельный конвеер 8500 был мощнее чем у NVIDIA. И Microsoft выпустил Shader Model 1.1, который по сути был «тем что делал 8500».

Это может показаться провалом со стороны D3D. Но провал и успех это вопрос относительный. Настоящий провал происходил в стане OpenGL.

NVIDIA любили OpenGL, поэтому когда вышел GeForce 3, они выпустили комплект расширений OpenGL. Проприетартных расширений, подходящих только для NVIDIA. Естественно, когда вышел 8500, он не мог использовать ни одно из них. 

Видите ли, в D3D v8 вы по крайней мере можете запустить шейдеры SM 1.0 на железе ATI. Естественно, чтобы использовать вкусности 8500 Вам придётся написать новые шейдеры, но Ваш код по крайней мере работал.

Чтобы получить хоть какие то шейдеры на 8500 в OpenGL, ATI пришлось написать несколько расширений OpenGL. Проприетартных расширений, подходящих только для ATI. Итак, Вам приходилось писать два пути выполнения кода, для NVIDIA и для ATI, чтобы иметь хоть какие то шейдеры.

Сейчас Вы наверняка спросите: «А чем занимался OpenGL ARB, чьей работой было поддержание OpenGL в актуальном состоянии?». Да тем же, чем занимаются большинство комитетов: тупил.

Видите ли, выше я упомянул ARB_multitexture потому что это тоже часть этой истории. С точки зрения внешнего наблюдателя ARB пытался вообще избежать добавления шейдеров. Они посчитали что если создать достаточно конфигурируемый конвеер с фиксированными фунцкиями он сможет сравняться по возможностям с шейдерными конвеерами.

И ARB стал выпускать расширение за расширением. Каждое расширение, в названии которого присутствовало «texture_env» было очередной попыткой залатать этот стареющий дизайн. проверьте реестр: между расширениями ARB и EXT таких вышло аж восемь штук. Многие вошли в основные версии OpenGL.

Microsoft в это время были участником ARB; они ушли примерно во время выхода D3D 9. Так что в принципе, вполне возможно что они каким то образом саботировали разработку OpenGL. Я лично сомневаюсь в этой версии по двум причинам. Во первых, им пришлось бы заручиться помощью других членов комитета, поскольку у одного участника только один голос. И, что более важно, во вторых, Комитету не нужен был Microsoft чтобы прийти к такому провалу. Чуть позже мы увидим что так и получилось.

Со временем ARB, скорее всего под натиском ATI и NVIDIA (очень активных участников) проснулся настолько чтобы принять шейдеры ассемблерного типа.

Хотите увидеть еще большую глупость?

Аппаратный T&L. Который в OpenGL появился раньше. Тут вот что интересно. Чтобы выжать максимальную производительность из аппаратного T&L, Вам необходимо хранить данные в GPU. В конце концов, именно в GPU они используются.

В D3D v7 Microsoft представил концепцию вертексных буферов. Это выделенные области памяти GPU для хранения данных о вертексах.

Хотите узнать когда в OpenGL появился свой аналог этого? О, NVIDIA, будучи фанатом всего что относится к OpenGL (до тех пор пока написанное остаётся проприетарным расширением NVIDIA), выпустили расширение для вертексных массивов еще при первом выпуске GeForce 256. Но когда ARB решил официально предоставить подобный функционал?

Два года спустя. Это случилось после того как они одобрили вертексные и фрагментные шейдеры (пиксели в языке D3D). Вот сколько времени заняла у ARB разработка кроссплатформенного решения для хранения данных в памяти GPU. Именно то, что нужно чтобы выжать максимум из аппаратного T&L.

Один язык чтобы всё разрушить

Итак, разработка OpenGL была раздроблена. Нет единых шейдеров, нет единого хранилища в GPU, когда пользователи D3D уже наслаждались и тем, и другим. Могло ли стать ещё хуже?

Ну… можно сказать и так. Встречайте: 3D Labs.

Кто они такие, спросите Вы? Это разорившаяся компания которую я считаю настоящими убийцами OpenGL. Естественно, общая вялось ARB сделала OpenGL уязвимым, когда он должен был бить D3D на всех фронтах. Но 3D Labs это возможно самая большая причина текущего рыночного положения OpenGL. Что они могли сделать такого?

Они разработали Язык Шейдеров OpenGL.

Дело в том что 3D Labs была умирающей компанией. Их дорогие ускорители стали ненужными когда NVIDIA усилили давление на рынок рабочих компьютеров. И, в отличие от NVIDIA, у них не было никакого присутствия на общем рынке; если бы NVIDIA победила, они бы исчезли.

Так и получилось.

И, в попытке остаться на плаву в мире, которому не нужна была их продукция, 3D Labs появились на Game Developer Conference с презентацией того что они назвали «OpenGL 2.0». Это должно было стать полностью переписанным с нуля API OpenGL. И это имело смысл; в API OpenGL было немало шероховатостей (примечание: они есть и сейчас). Просто посмотрите на что похожа загрузка и привязка текстур; это просто какая то чёрная магия.

Частью их предложения был язык шейдеров. Вот так. Однако, в отличие от текущих кросс-платформенных расширений ARB, их язык шейдеров был «высокоуровневым» (C это высокоуровневый язык для шейдеров. Нет, правда).

Итак, Microsoft в это время работали над своим собственным высокоуровневым языком шейдеров. Назвали они его, по своей давней привычке, «Высокоуровневым Языком Шейдеров» (HLSL). Но подход к языку был в корне другим.

Самая большая проблема языка шейдеров от 3D Labs была в том что он был встроенным. Видите ли, HLSL был языком, определённым Microsoft. Они выпустили для него компилятор, который генерировал ассемблерный код для Shader Model 2.0 (и последующих версий), который Вы вставляли в D3D. В дни D3D v9, HLSL никогда не вызывался из D3D напрямую. Он был удобной абстракцией, но совершенно необязательной. У разработчика всегда оставалась возможность отложить компилятор и доработать код до максимальной производительности.

В языке 3D Labs ничего этого не было. Вы скармливали драйверу код на C-подобном языке, и он возвращал шейдер. Всё, конец истории. И не ассемблерный шейдер, не то что можно вставить куда нибудь. Настоящий объект OpenGL, представляющий шейдер.

Это означало что пользователи OpenGL были беззащитны перед ошибками разработчиков, которые только начали разбираться с компилируемыми ассемблеро-подобными языками. Баги компилятора в новом языке шейдеров OpenGL (GLSL) ходили просто табунами. Что еще хуже, если Вам удавалось правильно скомпилировать шейдер для нескольких платформ (само по себе непростая задача), Вам всё равно приходилось иметь дело с оптимизаторами того времени. Которые были не так оптимальны, как могли бы.

Хотя это было главной проблемой GLSL, но не единственной. Далеко не единственной.

В D3D, как и старых ассемблерных языках OpenGL, можно было смешивать вертексные и фрагментные (пиксельные) шейдеры. Пока они использовали единый интерфейс, можно было использовать любой вертексный шейдер с любым совместимым фрагментным шейдером. Кроме того были уровни несовместимости, которые в принципе можно было терпеть; вертексный шейдер мог выдавать данные, которые фрагментный шейдер просто не читал. И так далее.

В GLSL ничего такого не было. Вертексные и фрагментные шейдеры были собраны в единую абстракцию, которую 3D Labs назвали «программный объект». И если Вам хотелось использовать вместе вертексные и фрагментные программы, Вам приходилось строить несколько таких программных объектов. И это было причиной второй проблемы.

Видите ли, 3D Labs думали что поступают очень умно. Они основали модель компиляции в GLSL на C/C++. Вы берёте .c или .cpp и компилируете в объектный файл. Потом Вы берете один или несколько объектных файлов и линкуете их в программу. Вот так и происходит компиляция в GLSL: вы компилируете шейдер (вертексный или фрагментный) в объект шейдера. Потом Вы помещаете этот объект шейдера в программный объект и связываете их вместе чтобы получить программу.

Хотя это позвляло делать некоторые потенциально крутые вещи вроде «библиотек» шейдеров, содержащих дополнительный код, который совместно использовали основные шейдеры, на практике это означало что шейдеры компилировались дважды. Один раз на этапе компиляции, один раз на этапе линковки. Не создавалось никакого промежуточного объектного кода; шейдер просто компилировался, результат компиляции выбрасывался и компиляция повторялась во время линковки.

Так что если Вы хотели связать Ваш вертексный шейдер с двумя разными фрагментными шейдерами, Вам приходилось компилировать куда больше кода, чем в D3D. Тем более что вся компиляция C-подобных языков происходила при разработке, а не при запуске программы.

У GLSL были и другие проблемы. Возможно неправильно винить во всём 3D Labs, потому что ARB в конце концов одобрила и приняла этот язык (но ничего кроме него из их предложения «OpenGL 2.0» не прошло). Но идея была именно их.

А вот действительно печальная часть. 3D Labs по большому счёту были правы. GLSL это не векторный язык шейдеров, каким всегда был HLSL. Так случилось потому что железо 3D Labs было скалярным железом (так же как современные карты NVIDIA), но в целом они были правы по части направления развития ускорителей.

Они также были правы с «compile-online» моделью для «высокоуровневых» языков. D3D впоследствии тоже на неё перешёл.

Проблема была в том что 3D Labs оказались правы в неправильное время. И в попытке призвать будущее слишком рано, в попытке его предугадать, они отбросили настоящее. Это также как OpenGL всегда имел возможность делать T&L. Если не считать того что конвееры T&L в OpenGL были полезны ещё до выхода аппаратной реализации, а GLSL был просто обузой прежде чем мир оказался готов его принять.

Сейчас GLSL — хороший язык. Но для своего времени он был ужасен. И OpenGL пострадал за это.

Приближается апофеоз

Хотя я и утверждаю что 3D Labs нанесли смертельный удар, именно комитет ARB забил последний гвоздь в крышку гроба OpenGL.

Эту историю вы наверняка слышали. Во времена OpenGL 2.1, OpenGL встал перед проблемой. У него было много старых неровностей. API было сложно использовать. Для каждого действия существовало по пять способов и никто не знал, какой окажется самым быстрым. Можно было «изучить» OpenGL по простым руководствам, но никто не говорил Вам какое API даст Вам максимум производительности.

И ARB решил сделать ещё одну попытку изобрести OpenGL заново. Это было похоже на «OpenGL 2.0» от 3D Labs, но лучше, потому что за ней стоял ARB. Попытку назвали «Longs Peak».

Что было не так с попыткой исправить старые API? Плохо было то что Microsoft в то время были уязвимы. Это было время выхода Vista.

В Vista Microsoft решили ввести давно необходимые изменения в драйверах дисплея. Они заставили драйверы обращаться к ОС для виртуализации видеопамяти и многих других вещей.

Хотя можно сомневаться в том было ли это необходимо, но факт остаётся фактом: Microsoft решили что D3D 10 будет только для Vista (и последующих ОС). Даже если у Вас было железо, способное выполнять функции D3D 10, Вы не могли запускать D3D 10 приложения без запуска Vista.

Вы также наверное помните, что Vista… ну, скажем просто что она получилась не очень. Итак, у Вас была тормозная ОС, новое API, работающее только на этой ОС, и новое поколение ускорителей которым было нужно API и ОС чтобы превзойти предыдущее поколение ускорителей.

Однако, разработчики могли бы получить доступ к фунциям уровня D3D 10 через OpenGL. Ну, смогли бы, если бы ARB не были так заняты работой над Longs Peak.

По большому счёту, ARB потратил полтора-два года на то чтобы сделать API лучше. Когда вышел OpenGL 3.0, время Vista уже заканчивалось, на горизонте появилась Win7, и большинство разработчиков уже не интересовались фунцкиями D3D-10. В конце концов, железо для которого предназначался D3D 10 замечательно работало с D3D 9. А с расцветом портов с PC на приставки (или PC-разработчиков, занявшихся разработкой для приставок) функции класса D3D 10 оказались невостребованы.

Если бы у разработчиков был доступ к этим функциям раньше, через OpenGL на машинах с WinXP, разработка OpenGL получила бы так необходимый импульс. Но ARB упустил эту возможность. И знаете что самое плохое?

Несмотря на то что два ценных года были потрачены на разработку API с нуля… они всё равно провалились и вынуждены были вернуться к предыдущей версии.

То есть, ARB не только упустили замечательную возможность, но и не сделали ту задачу, ради которой возможность была упущена. Просто полный провал.

Это и есть история борьбы OpenGL и Direct3D. История упущенных возможностей, огромной глупости, слепоты и просто безрассудства."
"Время летит! Всего месяц назад мы стартовали IntelliJ IDEA 2016.2 EAP, а уже сегодня рады представить вашему вниманию Public Preview. Предлагаем вам убедиться в том, что этот месяц не прошел даром, прочитав этот пост. Нетерпеливые могут его пропустить и пойти сразу качать превью, чтобы попробовать все самостоятельно. Для остальных предлагаю короткий рассказ об основных улучшениях.




Отладчик

Продолжая бороться за пространство и общее удобство, мы объединили вкладку Watches с вкладкой Variables.



Также теперь можно использовать многострочные выражения в настройке брейкпойнта в полях Condition и Evaluate and log, и в настройках Data Type Renderers в поле Use following expression.



Интеграция с Git и Mercurial

Вкладка Log для Git и Mercurial в очередной раз претерпела ряд изменений. Ее содержание теперь обновляется в фоновом режиме (и при загрузке проекта, и при изменениях в локальном репозитории). За счет этого открываться вкладка стала гораздо быстрее.

Кроме того, во время обновления и загрузки под панелью инструментов теперь отображается тонкая полоска прогресса. 



Если в поле Filter указана строка поиска, во время прокрутки внизу также появляется индикатор загрузки.

Подробная информация о коммитах показывается теперь для нескольких выделенных коммитов.

И наконец, можно установить шорткат для быстрого перехода к полю Filter.

Для Git мы исправили важную проблему, с которой наверняка сталкиваются пользователи Windows и OS X: переименование файлов, где меняется только регистр символов.

Работа с патчами

Если вы скопируете патч в буфер обмена и переключитесь в IDE (или перетащите патч в окно IDE мышью), вам автоматически предложат применить этот патч.

Кроме того, применение патча значительно упростилось в тех случаях, когда он не содержит информации о ревизии, а оригинальный файл был перенесен, переименован или изменен. В простейших случаях IDE постарается самостоятельно определить оригинальный файл, в сложных — предложит вам его указать. Также, если содержание файла изменилось, IDE поможет объединить эти изменения с патчем.



И наконец, перед применением патч теперь можно просто сравнить с локальной копией (кнопка Show Diff) и при необходимости внести изменения в локальную версию вручную по ходу сравнения.

Редактор

Редактор теперь поддерживает шрифты с лигатурами — специальными символами, образованными путем соединения других символов. Включить опцию можно в Settings → Editor → Colors & Fonts → Font (флажок Enable font ligatures). Убедитесь, что выбранный шрифт поддерживает лигатуры, например FiraCode, Hasklig, Monoid или PragmataPro.



Интерфейс

Внешний вид IDE теперь можно настроить под себя, выбрав любое изображение как фон редактора и окна IDE. За счет настроек прозрачности это прекрасно работает и с темной, и со светлой темами.

Изображение выбирается с помощью действия Set Background Image, которое доступно как из Find Action, так и из контекстного меню на файле изображения.



Также внешне изменились всплывающие нотификации. Теперь они отображаются в нижнем правом углу (ближе к окну инструментов Events), имеют более компактную форму и группируются по типу подсистемы.



Spring Framework

Поддержка Spring Framework продолжает совершенствоваться.

Мы добавили инспекцию, которая предлагает автоматически заменять инжектирование полей конструкторами. Поддержали опцию (добавленную в Spring 4.3), которая позволяет использовать параметризированные типы (generics) в качестве классификаторов (qualifiers). Поддержали пользовательские аннотации EventListener, определенные с помощью AliasFor.



Кроме того, готова основательная поддержка Spring Cache (абстракции, добавленной в Spring 3.0 и полностью обновленной в Spring 4.1). Поддержка включает навигацию, инспекции, подсветку синтаксиса, автодополнение и навигацию при редактировании SpEl, и многое другое.



Для Spring MVC внутри шаблонов Freemarker и Velocity появилось автодополнение и навигация для переменных, объявленных в контроллере.



Также мы поддержали изменения Spring Security 4.0 и добавили автодополнение и навигацию при редактировании SpEl и для аннотаций и внутри XML.



Плюс мы добавили подсветку и навигацию для сообщений от Spring в консоли.

JavaScript

Теперь IDE не только помогает в написании ES6 кода, но и предлагает конвертировать в него код более старых версий JavaScript. Новый intention сможет заменить нормальные анонимные функции на стрелочные функции (arrow functions) и короткие стрелочные функции (shorthand arrow functions).



В дополнение к постфикс-автодополнениям, реализованным ранее, мы добавили шаблоны .const и .let.



React

IDE научилась понимать свойства (props) компонентов, объявленные при помощи propTypes, и теперь предлагает автодополнение и навигацию.



Методы жизненного цикла компонентов (например, componentDidMount) больше не подсвечиваются как неиспользуемые.

Когда вы передаете компоненту обработчики событий (например, onClick, onChange), IDE вместо кавычек ставит фигурные скобки (как и положено).

К слову о кавычках, теперь в Settings → Editor → Code Style → HTML → Other → Generated quote marks вы вообще можете указать, что использовать: двойные кавычки, одинарные или вообще ничего.



Наконец, IDE научилась понимать non-DOM аттрибуты, такие как key, ref и dangerouslySetInnerHTML.

AngularJS

Для AngularJS 2 мы добавили много полезных шаблонов (live templates). В Project Wizard → Static Web появился раздел Angular CLI.



TypeScript

IDE предлагает умное автодополнение для enum-типов.



Npm, Gulp и Grunt

Любой скрипт npm, Gulp и Grunt может теперь автоматически запускаться IDE перед запуском Run configuration. Для этого этот скрипт необходимо добавить в разделе Before launch в диалоге Run configuration.



Работа с базами данных

По мере развития DataGrip, нового продукта JetBrains, инструменты для работы с SQL и базами данных внутри IntelliJ IDEA также продолжают улучшаться.

В диалоге настроек Data Source and Drivers появилось автодополнение для поля Database.



В окне инструментов Database появилась опция Auto-scroll from Editor. При открытии того или иного элемента базы данных в редакторе, этот элемент выделяется в окне Database.



Автодополнение SQL стало еще больше учитывать контекст. Например, если в контексте ожидается имя таблицы, IDE больше не предлагает функции.



Surround With предлагает передать текущее выражение в качестве параметра функции.



Редактор таблицы предлагает автодополнение при редактировании значения таблицы (на основе других значений этого столбца).



Размеры столбцов таблицы можно менять с помощью шорткатов Ctrl + Shift + Вправо/Влево (⌘⇧→← для OS X).

Для PostgreSQL была добавлена поддержка Schema Search Path, а также Range-типов и типов с TimeZone.

Установщик

И наконец, установщик для Windows теперь также включает наш кастомный билд JDK с нашими исправлениями проблем с фокусом и рендеринга шрифтов.

Вот, пожалуй, и все основные нововведения. Теперь можно смело скачивать превью и пробовать его самостоятельно! Как всегда, я с удовольствием отвечу на ваши вопросы в комментариях.

Программируйте с удовольствием!"
"

I18n.locale = :ru — это новости о Ruby/Rails и связанных технологиях на Google+.

UPDATE: черзе год после вышеописанных событий, мы открыли (в дополнение к G+) и рассылку CodingDead. И вот зачем.
Из описания:
1-3 сообщения в день, безопасная для просмотра в офисе информация, не исползуется для рекламы или спама *.
* Оставляем за собой право на нецензурную брань в комментарих к статьям типа: ‘Why Ruby / Rails / #{your_favorite_gem} sucks‘, a также право на рекламу опенсорс технологий и событий Rails-собщества"
"Вышла из беты 7 версия программы быстрого создания интерактивных прототипов Axure RP PRO. Владельцы предыдущих версий могут обновиться бесплатно. В этом посте хотел бы пробежаться по нововведениям, которые порадовали меня больше всего.



Приятно было наблюдать, как во время беты с завидной периодичностью выходили обновления, которые делали программу ещё лучше.

UI
Пристальное внимание было уделено интерфейсу. Появилось огромное количество горячих клавиш для основных действий, добавился быстрый переход с помощью табуляции между элементами отдельного экрана или между самими экранами (ctrl+tab). Уменьшилось количество переключений между клавиатурой и мышкой, уменьшилось расстояние между элементами управления в рамках распространённых пользовательских сценариев.

Интерактив
Добавилось множество действий, которые пользователь может выполнять в сгенерированном прототипе и получать обратную связь. Двойной клик, длинный клик, наведение мышкой на элемент, свайпы, нажатие клавиш. События с окном браузера: изменение размера, скроллинг, клик правой кнопкой мыши и так далее. Все эти и многие другие действия теперь к услугам проектировщиков.
Список может получиться внушительным, но я обещал рассказать только о самом интересном.
Действия с динамическими панелями:
— Можно выдернуть первое состояние динамической панели на рабочую область;
— Со всеми виджетами теперь можно делать то, что раньше можно было делать только с динамическими панелями: прятать, двигать, изменять z-index;
— В событии «show» для виджета можно указать один из видов поведения, на эмуляцию которого раньше уходило кучу времени: lightbox, выпадающее меню, перенести на верхний слой сцены. А ещё теперь можно сделать так, чтобы при появлении скрытого виджета все остальные смещались вниз на расстояние, равное размеру этого виджета.

Генерация прототипов
Добавилась кнопка «Превью». Теперь можно смотреть промежуточные результаты в браузере без генерации прототипа. Причём, изменения применяются мгновенно.
Добавилась возможность прицеплять любые шрифты, но это скорее для UI, чем для UX. Но многих порадует, да!
В сгенерированном прототипе можно подсветить все кликабельные элементы.
Теперь все ссылки в браузерной строке выглядят по-человечески. Можно давать клиенту ссылку на любую страницу прототипа, больше не заморачиваясь со специальной кнопкой в дереве сайта.

Стили
Так как теперь прототипы генерятся по стандарту html5, то и появились соответствующие стили: внутренние и внешние тени для виджетов (включая текстовые), уровень прозрачности любого виджета (включая картинки), фон для динамических панелей и так далее.

Свойства виджетов
Тут почти всё оказалось полезным.
— Значения по умолчанию для текстовых полей, которые исчезают при клике по ним;
— Типы текстовых полей (email, телефон, url и так далее). Это нужно для того, чтобы на мобильных устройствах появлялась нужная клавиатура при клике по ним;
— Автоматическая ширина и высота текстовых виджетов. Этого нам не хватало с самого начала. Теперь не нужно выставлять ширину текстового виджета на глазок с небольшим запасом для разных браузеров;
— Действия в динамической панели теперь могут обращаться к объектам вне этой динамической панели. То есть, теперь я могу сделать без бубна, чтобы при клике на кнопку в одном из состояний динамических панелей, что-нибудь произошло в одном из состояний другой динамической панели на этой же странице (или в мастере, если угодно).

Адаптивные виды
Да, теперь можно делать адаптивные прототипы. Для каждого адаптивного вида нужно будет рисовать отдельный вариант и указывать, при какой ширине окна браузера он будет отображаться.

Репитеры
Наверное, хорошая штука, но пока не вижу ни одного способа прикладного использования. В двух словах: они позволяют эмулировать списки с фильтрами и постраничными навигациями. Но на практике быстрее получается оформлять списки по старинке в статике и на мастерах.
Хочу закончить обзор на том, что я перечислил лишь крохотную часть изменений в семёрке. Я работаю с этой версией с первой беты и по сравнению с 6.5 скорость работы возросла не меньше, чем на 40%. Это достойный показатель. 

Стоимость стандартной версии продукта — 289$ и в этот раз он стоит этих денег. Как обычно, можно в течение 30 дней попользоваться бесплатной версией.

Ах, да, чуть не забыл! Сервис для публикации прототипов axshare теперь стал бесплатным и все ограничения, наложенные на не-про аккаунты, теперь сняты. Вы можете публиковать 1000 прототипов до 100 мегабайтов каждый, кастомизировать входную страницу и домен, на котором будут размещены прототипы.

В связи с релизом полностью обновился официальный сайт Axure. Появились новые видеоуроки (пока суммарная длительность — около часа) и переписаны старые статьи.

Если у вас трудности с английским и возникают вопросы по работе, обращайтесь ко мне в группу, там тепло и уютно и все готовы помогать друг-другу.

Также периодически я выкладываю туториалы по распространённым задачам на своём канале на ютубе."
"«Всем привет, меня зовут Егор Камелев и сегодня я расскажу вам…»
Если вы уже слышали эти слова, то, скорее всего уже встречались с одним или несколькими из моих обучающих видео по работе в Axure. Прошло уже довольно много времени с тех пор, как я добавил первое из них (тогда ещё для Акшуры какой-то древней версии), и я решил сделать некий сводный список того, что уже есть, чтобы вам не пришлось мучиться с поиском на моём канале. Да, конечно, в этом списке только те ролики, которые имеют отношение в Акшуре седьмой версии! Итак, поехали.

Быстрое прототипирование в Axure
На сегодняшний день самый популярный ролик, т.к. там показан реальный процесс работы над гипотетическим круглым проектом в вакууме. Качество звука оставляет желать лучшего, но никого это, похоже, не смущает.

Я поставил его на первое место, потому что он больше всего подходит тем, кто вообще ни разу не работал в Акшуре и хочет посмотреть, что там и как. Дальше попробую предоставить вам лаконичный список.

Уроки проектирования
Первые ролики из серии, рассказывающей не столько об Акшуре, сколько о принципах проектирования тех или иных вещей.

Универсальный каталог

Форма авторизации

Загрузчик файлов

Уроки работы в Axure 7
Должен заметить, что я не брал ничего с официального сайта Акшуры. Все материалы, которыми я делюсь, наработаны годами методом проб и ошибок и пониманием того, какие штуки использовать оптимальнее в тех или иных случаях.

Приклеиваем меню навигации к странице при скроллинге

Глобальные переменные

Активный пункт в меню навигации

Якоря

Разворачивающиеся вопросы и ответы

Выпадающее меню

Эффект параллакса

Адаптивные прототипы

Автоматическое формирование цены в форме заказа

Прокрутка в мобильных приложениях

Делаем табы без использования динамической панели

Всё о всплывающих окошках

Встраиваем видео, карты и другие объекты в прототипы

Текст и локальные переменные

Кнопка сравнения товаров

И это не всё. Также за это время было проведено несколько вебинаров, вот они:

Быстрое прототипирование в Axure: часть 1 и часть 2

Второй вебинар Проектората: часть 1, часть 2, часть 3

А третий, с названием «Проектирование в IT: методология от А до Я», был платным, и вы его сами сможете найти при желании.

Чтобы этот пост принёс много пользы и вам, и мне, я предлагаю в комментариях высказывать пожелания по следующим урокам и вебинарам. Разумеется, самые заплюсованные будут рано или поздно воплощены в жизнь. За обновлениями следите в моей группе в контакте.

До встречи!"
"

Если коротко, то это аппаратное расширение для ускорения работы с vim.

Когда педаль нажата, vim переходит в Insert Mode. Когда отпущена, происходит нажатие Escape, и вы возвращаетесь в Normal Mode.

Автор проекта — Александр Левчук.

Всем чудных выходных!"
"Google готовится удвоить усилия по открытию беспроводной индустрии. Ларри Пейдж недавно говорил о FCC и ее успехах (скорее, их отсутствии) в борьбе за незанятые радиочастоты (об этом — в другой статье), а недавно опубликованный патент Google в деталях описывает план, способный дать беспроводной индустрии легкий способ открыть свои сервисы для всех потенциальных клиентов и конкурировать с другими операторами по ценам и покрытию.


Сейчас мобильные устройства могут переключаться между сетями различных операторов. Wi-Fi устройства могут подключаться к хотспотам, если они доступны. Например, устройства T-Mobile уже могут автоматически переключаться на хотспоты T-mobile-run, разгружая сотовую сеть. Это шаг в правильном направлении, но Google хочет совершить настоящий рывок в этой области.
 
Вкратце, Google предлагает следующее. Телефон (или другое устройство) опрашивает ближайшие точки доступа и получает с них список предоставляемых услуг с ценами (голосовая связь, VoIP, передача данных и т.д.). После этого аппарат самостоятельно (или с помощью владельца) определяет услугами какого оператора выгоднее всего воспользоваться на этой точке. Дополнительный плюс в том что на точке оператор может выключаться из «торгов» — например, если его канал для этой точки занят полностью. Дополнительно в систему включена возможность перевода микроплатежей. 
 
 Для внедрения такой схемы есть несколько проблем, одна из которых — любовь операторов к фиксированным тарифным планам, не только обеспечивающим компании стабильный доход и лояльность клиентов, но и достаточно простым и понятным для пользователей.
 
 Впрочем, многие компании уже движутся в нужном направлении. Уже упоминавшиесся хотспоты T-Mobile, ""открытый доступ"" Verizon и планы BYOD (Bring your own device) понемногу открывают стены, разделяющие операторов беспроводного доступа."
 
 
"Хотя многие [американцы — прим. переводчика] жалуются на строгость законов об иннтеллектуальной собственности в США, Европейские суды в очередной раз доказывают — всё могло быть гораздо хуже. Последнее напоминание пришло из Германии, и касается права на создание миниатюр (thumbnails) из изображений. Немецкий суд решил что это нарушает авторские права создателя изображения.


Google давно не везёт в Европейских судах. В прошлом году Google проиграл в суде бельгийской газетной ассоциации, заявившей что цитаты из новостей, использующиеся в результатах поиска Google News, нарушают её копирайт. Контент бельгийских газет исчез из Google News, но Google не сдаётся — сейчас в суде рассматривается апелляция.

В последнем случае Google был признан виновным в нарушении авторского права фотографа и художника комиксов. По материалам Bloomberg News, Google проиграл оба этих дела, суд постановил что изменение изображения «не может быть признано созданием самостоятельного произведения», поставив таким образом создание миниатюр вне закона.

Ещё один любопытный момент. Хотя авторы защищённых работ могут самостоятельно запретить доступ к нужным изображениям для поисковых роботов, суд признал что поисковая система обязана самостоятельно каким то образом исключать защищенные авторским правом работы. Так как автоматически это делать сейчас невозможно, решение суда скорее всего приведёт к радикальным изменениям в немецкой версии Google Image Search.

Вряд ли Google единственный столкнётся с подобным отношением. Похожее дело недавно было инициировано сайтом Perfect 10 — на этот раз против Microsoft. Тем временем уже упомянутые бельгийские газеты снова подают иск — на этот раз против Евросоюза. Похоже, следует ожидать санкций и против других сервисов поиска изображений в Германии."
"Привет, Хабр! Три года назад мы приняли стратегическое решение принять участие в разработке go-lang-idea-plugin, опенсорсного проекта, нацеленного на создание IntelliJ-плагина для Go. За эти три года наш вклад (в сумме около 3000 коммитов) помог полностью переписать плагин, сделав его более стабильным, расширяемым и функциональным.

В прошлом году мы начали подсчет количества уникальных пользователей плагина. За год оно выросло вдвое и теперь составляет 30 тысяч активных пользователей в месяц. Это, а также большое количество пользователей, ждущих от нас Go IDE уровня IntelliJ IDEA, вместе убедили нас наконец «форкнуть» go-lang-idea-plugin и создать собственную IDE для Go.

Сегодня мы рады представить вашему вниманию Gogland, новую Go IDE и последнее пополнение семейства IDE на базе платформы IntelliJ! Хотя Gogland находится в активной разработке, сегодня мы начинаем «закрытое» тестирование. Это означает, что у вас есть шанс одними из первых опробовать Gogland.

Больше подробностей о Gogland можно узнать на официальном сайте. Также не забудьте ознакомиться с FAQ. 

Чтобы получить доступ к закрытому тестированию, заполните форму на сайте.



Gogland — рабочее название; окончательое название IDE будет другим. Если у вас есть идеи названия, присылайте их нам!

Команда Gogland
www.jetbrains.com/go"
"В песочнице

С момента релиза, прошедшего несколько недель назад, любопытные разработчики изучали исходный код нового браузера от Google. Исходники Хрома интересны по многим причинам: тут и новая JavaScript-машина V8 с хорошим приростом производительности в некоторых задачах, движок WebKit, обрабатывающий и показывающий web-страницы, и наконец «песочница», изолирующая компоненты в Chrome друг от друга. Именно эта система привлекла внимание многих программистов, по простой причине. При чтении исходников создается впечатление что Google декомпилировали (reverse-engineered) компоненты Windows — а это запрещено лицензионным соглашением.



Но перед тем как мы рассмотрим вопрос реверс-инжиниринга, стоит взглянуть на сам браузер.

Архитектура безопасности Chrome

ИЗ всех нововведений браузера его архитектура безопасности — самое интересное и значительное. Традиционные браузеры (Firefox, Internet Explorer 7 и ниже, Opera, Safari) создают один процесс для всего — отображения интерфейса, соединения с Интернет, парсинга HTML, запуска плагинов. Все вкладки браузера используют этот процесс.

Эта модель «одного процесса» имеет много недостатков, самый очевидный из которых — стоит чему то пойти не так (баг движка отрисовки или одного из плагинов), и браузер отправляется в цифровую Валгаллу целиком. Такая архитектура также имеет и менее заметные особенности. Например, в идеале код выполняющийся в плагинах или движке JavaScript не должен иметь доступа к некоторым ресурсам — например, писать файлы на диск. Но так как все компоненты выполняются в рамках одного процесса, обеспечить такое поведение непросто.

Redmond снова впереди

Windows Vista и IE7 на самом деле опередили Google в отходе от такой модели. В Internet Explorer уже давно применяется концепция ""зон безопасности"", позволяющая разграничить привилегии для интранета и глобальной сети. Одним из постоянных источников багов в IE было то что специально сформированная страница может «обмануть» браузер и выполняться так будто находится в доверенной зоне. Чтобы избавиться от этой проблемы, в Vista запрещено смешивать источники из разных зон в рамках одного процесса. Если после просмотра сайтов из зоны Internet вы открываете внутренний корпоративный сайт, создается новый экземпляр процесса iexplore.exe, и они действуют отдельно.

Internet Explorer 8, выпущенный в виде бета-релиза в этом году, продвинулся ещё дальше в этом направлении. Вместо одного процесса на зону IE8 использует один процесс на каждую вкладку, плюс один родительский процесс, отвечающий за интерфейс. Это обеспечивает еще лучшую изоляцию. В IE8 даже вкладки в пределах одной зоны безопасности независимы и изолированы друг от друга. Эта архитектура решила еще одну давнюю проблему — теперь скоропостижная смерть одной вкладки не влияет на остальные.

IE8 и предотвращение выполнения данных (DEP)

Другая фича IE8 — поддержка DEP — предотвращение выполнения данных, разработанная чтобы раз и навсегда разделаться с выполнением кода при buffer overflow. Традиционно в архитектуре x86 память может помечаться как чтение-и-выполнение и/или запись. Если было разрешено только чтение, выполнение разрешено. Это привело к возможности сделать buffer overflow — запросить память под временное хранилище (ей выставляются чтение и запись), и поместить туда маленький кусочек исполняемого кода.

С DEP, чтение и запись больше никак не связаны; область памяти может быть помечена как «чтение+запись», без флага выполнения. К сожалению, иногда необходимо создавать области где разрешено «чтение+запись+исполнение». Частый случай — JIT (just-in-time) компиляторы, вроде Java и .NET. Эти программы могут создавать исполняемый код в процессе выполнения, поэтому им надо выделить память, записать туда информацию и потом пометить область для исполнения.

Хотя в x86 нормальная поддержка DEP появилась сравнительно недавно, в Win32 API давно поддерживаются соответствующие функции. Сознательные разработчики корректно обрабатывали DEP даже если это строго не требовалось, чтобы обеспечить совместимость не только со старыми процессорами, но и с будущими (на которых мы сейчас работаем). Однако, ленивые разработчики просто забивали на такую «необязательную» вещь. Поэтому некоторые старые Windows-программы не могут выполняться с DEP — в том числе, некоторые плагины ActiveX.

Чтобы обеспечить совместимость с этими плагинами, разработчики IE7 выключили поддержку DEP по умолчанию. С момента выхода этого браузера многие плагины уже обновились (разработчики поняли, что совсем скоро это станет обязательным требованием), и IE8 уже включает DEP по умолчанию.

Что и приводит нас к Chrome. Как и IE8, Хром создает один процесс на каждую вкладку. На самом деле он идет ещё дальше, создавая дополнительный процесс для каждого плагина. И, как и IE8, Хром включает DEP для всех своих процессов.

Где же здесь reverse-engineering, спросите вы? Если покопаться в исходниках Хрома, можно увидеть интересную вещь.

Сначала Chrome пытается использовать стандартный API для управления DEP. Однако, если это не получается, он пробует второй способ:

// Completely undocumented from Microsoft. You can find this information by
// disassembling Vista's SP1 kernel32.dll with your favorite disassembler.


(цитата из кода браузера).

Большинство используемых функций полностью официально задокументированы — например CreateProcess описана очень хорошо. NtQueryFullAttributesFile — уже недокументированная функция. Для создания процессов в Chrome используются и те, и другие."
"

Широко известны сайты для решения олимпиадных задач по программированию, такие, как, например, TopCoder и Codeforces, а также сборники математических задач-головоломок, например, Project Euler. За последний год произошёл бум онлайн образования: возникли стартапы Coursera и Udacity, предоставляющие онлайн курсы от топовых университетов США… но для тех, кто хочет изучить биоинформатику, пока ничего нет.

Розалинд — проект, разрабатываемый в Санкт-Петербуге и University of California, San Diego с мая 2012 года, как раз заполняет эту нишу. Это платформа для обучения биоинформатике с помощью решения задач, бесплатная и открытая.

Всё обучение строится вокруг задач, которые и составляют основное содержание сайта:



Каждая задача содержит биологическое обоснование и строгую формулировку, достаточную для формального решения. Например, в двенадцатой задаче необходимо из небольших фрагментов ДНК собрать геном. Также там рассказывается, что такое секвенирование и зачем это нужно:



Пользователь может решать задачи на любом языке программирования и даже на бумажке, но после скачивания с сайта тестового датасета у него будет лишь пять минут для его обработки. Если ответ неверный, ничего страшного, можно пробовать неограниченное количество раз, но при этом датасет каждый раз генерируется заново.

Не все задачи можно решать сразу, вернее, сразу можно решить только первую. Задачи выстраиваются в граф зависимостей, чтобы процесс обучения был осмысленнее и материал осваивался по порядку. Но если вас больше интересует, например, только сборка геномов (genome assembly), либо выравнивание (sequence alignment), либо вычислительная протеомика (computational proteomics), то можно углубиться в определённом направлении по графу зависимостей и не решать другие задачи. Таким образом, полученные знания будут глубже в выбранной теме.



И, конечно, на сайте есть профили, а также зачатки игровой механики: уровни и бейджи.





Надеюсь, Розалинд будет полезен всем, кто хочет окунуться в этот интереснейший мир биоинформатики или просто изучить что-то новое. 

Проект активно развивается, поэтому мы с радостью выслушаем любую критику. В частности, 26 августа в Петербурге пройдёт международная конференция RECOMB Bioinformatics Education, одной из главных тем которой станет Розалинд.

Система уже поддерживает переиспользование задач в своих курсах, так называемые «профессорские аккаунты», благодаря чему мы внедрим Розалинд в образовательный процесс UCSD и Harvey Mudd весной 2013. Для России это не так востребовано, потому что программ по биоинформатике особо-то нигде и нет. Но с Розалинд это становится проще, — может быть, появятся?

Мы постоянно добавляем новые задачи: сейчас их 42 и примерно столько же находятся в черновиках. Недавно появилась возможность принимать и курировать пользовательские идеи для задач, чтобы биоинформатическое сообщество смогло участвовать в процессе создания контента. 

В планах видеозапись лекций по биоинформатике в UCSD и создание нескольких онлайн курсов на основе этого материала.

P.S. Проект назван в честь Розалинд Франклин, чьи исследования привели Уотсона и Крика к открытию спиралевидной структуры ДНК. Розалинд умерла от рака за четыре года до присуждения Нобелевской премии за это открытие, в 37 лет, так как имела наследственную предросположенность и много работала с радиацией."
"Дерек Поважек (о котором на Хабре уже писали) выложил в своём блоге статью об организации системы комментариев на новостном сайте. Встречайте.

Вот 10 способов, которые новостной сайт может использовать чтобы улучшить качество комментариев. (На самом деле их гораздо больше, но ни один редактор не устоит перед искушением создать список «10 самых-самых»).


1. Требуйте регистрации

Анонимность важна в журналистике, но не для комментариев.

Есть множество веских причин разрешить анонимность, особенно в новостях. Иногда источнику нужно высказаться против нанимателя или правительства, не называя себя. Отлично. Но нет никаких причин, действительно ни одной причины, чтобы разрешать людям писать комментарии, не зарегистрировавшись для начала.

Просто введя обязательную регистрацию, вы избавитесь от 80% своих проблем с комментариями. Если важно разрешить анонимные высказывания, можно дать пользователю возможность убрать своё имя с отдельных комментариев, оставив необходимость писать из-под учетной записи. (Другими словами, пользователь должен войти под своим именем чтобы система могла их опознать, но он может комментировать как «Аноним». Анонимные комментарии при этом помещаются в очередь на модерацию чтобы исключить злоупотребления).

2. Устанавлийте правила и обеспечивайте их соблюдение

Никто не любит узнавать о правиле уже после нарушения. Напишите понятный человеку набор правил сообщества (правила Хабра — отличный пример). Пусть пользователям нужно будет согласиться с ними в процессе регистрации, и оставляйте ссылку на них в каждой форме комментария. В этом случае при необходимости вы сможете сказать «Мы вас предупреждали».

Потом придерживайтесь этих правил. Удаляйте плохие комментарии и отмечайте хорошие. Существует распространённое заблуждение, что модерация комментариев — это большая ответственность. Это не так. Управление вашим сообществом обычно не означает для вас особой дополнительной нагрузки.

3. Назначьте управляющего сообществом

Если вы не можете назвать управляющего сообществом — это, возможно, вы.

Вы бы не позволили писателю публиковать свою работу без редакторской правки — так почему позволять это комментаторам? Если вы даёте людям возможность оставлять комментарии на вашем сайте, кто то должен их проверять. Думайте о них как о редакторах в издательстве.

Вам не обязательно читать каждый комментарий перед размещением его на сайте, кто то обязательно должен удалять те из них, которые нарушают установленные в сообществе правила. Как граффити в пространстве города, плохие комментарии притягивают других подобных комментаторов. Но модераторы сообщества должны быть более чем просто полицейскими — они должны быть соединяющим звеном между командой проекта и участниками. Они должны подавать пример, участвовать в дискуссиях и помогать новичкам, а также делать периодический «прогноз погоды в сообществе» для команды, чтобы обратную связь от участников можно было использовать.

4. Управляйте вводом

Хотя пользователи могут самостоятельно писать комментарии, это не означает что вы не можете им помогать.

Когда то, во времена когда мы вели комментарии на сайте Fray, мы постоянно улучшали поведение формы для комментария. Если вы пытались отправить что то слишком длинное, она просила вас переформулировать покороче. Если комментарий был слишком мал, вам предлагалось высказаться более развёрнуто. Если вы писали ЗАГЛАВНЫМИ, мы приводили предложения к нормальному виду (Flickr делает это и сейчас). Это совсем несложно для компьютера, и имеет большое значение для пользователей.

5. Позвольте сообществу помогать вам

Если вы считаете что плохие комментарии вас раздражают, то хороших комментаторов они раздражают вдвое больше.

Да, вы можете платить кому нибудь из команды и сделать его модератором сообщества. Кроме того, вы можете дать сообществу возможность действовать самостоятельно. Дайте каждому комментарию кнопку «-». Потом сделайте для управляющего страницу, где он мог бы видеть комментарии, набравшие наибольшее число голосов «против», и принять соответствующие меры.

Дополнительно, можно дать каждому комментарию кнопку «+», чтобы пользователи сообщали вам о хороших комментариях. Помните о том, что пользователи — не враги: они тоже хотят содержать сайт в чистоте.

6. Объединяйте истории и комментарии

Худшее, что вы можете сделать — отделить комментарии от контента. Это создает «неофициальный» канал, где пользователи могут вести себя неадекватно, потому как — почему бы и нет? Всё равно они «за детским столиком».

Так что связывайте истории и обсуждения как можно плотнее. Это даст обсуждению центральную тему.

7. Разрешите личные сообщения

Интернет не пишет злобных писем редактору, он он определённо способствует этому. И это нормально — иногда людям нужно спустить пар. Ваша работа — управлять паровым клапаном.

Комментарии к некоторым новостям столь безумны потому что у читателя нет другого способа ответить. Люди с удовольствием пообщаются с вами один на один, если вы предоставите им такую возможность.

Так что создайте форму, используя которую человек сможет отправить письмо редакторам, и оставьте ссылку на неё в форме добавления комментария. Скажем, «Если хотите отправить личное сообщение, нажмите здесь.»

Таким образом вы можете получить несколько гневных писем, но лучше пусть они будут в вашей почте, чем на сайте, где они лишь добавят масла в огонь.

8. Участвуйте...

Позвольте своим писателям участвовать в дискуссии. Люди быстро остывают, когда понимают что автор новости читает их сообщения (и действуют гораздо решительнее, когда думают что никто их не слышит). Я знаю, писатели могут считать это дополнительной нагрузкой к работе, и скорее всего заранее возненавидят такую обязанность. Очень жаль. Это часть эволюции журналистики — либо ты на борту, либо нет.

Хороший способ вовлечь писателей в обсуждение их историй — разрешить им модерировать комментарии к их собственным статьям. Им можно делать это в их блоге, и у них должна быть такая же возможность в их историях (под присмотром управляющего сообществом, естественно).

9. … Но не кормите троллей

Участники с благими намерениями обычно довольны, когда авторы участвуют в обсуждениях. К сожалению, это может привлечь и троллей — пользователей, играющих в игру «сожрать столько вашего времени, сколько возможно».

Обучите ваших авторов поведению в онлайн-сообществе. Если кто то пытается вывести вас из себя, не поддавайтесь. Хороший управляющий может помочь авторам понять, когда и как следует вступать в дискуссию.

10. Отпустите управление

Новостные сайты — иерархически организованные сообщества, в отличие от Интернета. Привыкните к факту что люди в сети не станут следовать вашим указаниям. Вообще, единственное на что можно рассчитывать — неожиданности. Когда это произойдёт, о вас будут судить по вашим дальнейшим действиям. Готовьтесь к сюрпризам.

Источник: Механический мир"
""
"Эм… они какбэ говорят нам: 

Я конечно люблю ФФ, и Яндекс мне симпатичен. Но причем здесь ЭТО, да еще и на ЛастФМ?"
"Здравствуйте!
Вас приветствует Администрация сайта Вконтакте.ру!

В последнее время участились проблемы с доступом к сайту Вконтакте.ру.
В связи с эти нами был запущен альтернативный сервер для входа на наш портал!

Т.к. наш основной сервер перегружен и довольно часто возникают проблемы со входом и низкой скоростью работы сайта мы предлагаем вам воспользоваться нашим новый дополнительным адресом vkontakt.tut.su. Этот адрес служит для альтернативного входа и работает даже когда наш основной сайт временно не доступен или доступен ограниченно. Помимо того, скорость работы нового сервера намного выше, чем у основного за счет меньшей нагрузки. 

Надеемся, что пользование нашим порталом для вас теперь станет более легким.

С уважением Администрация сайта Вконтакте.ру.

Йо-майо… 21 век на дворе…"
"Не бойтесь, я не собираюсь вам ничего продавать. Да и пиариться не собирался. Просто не нашёл, в какой ещё хаб Хабра или Мегамозга можно опубликовать эту статью. Просто расскажу историю. Постараюсь покороче.

Когда-то давным-давно я купил несколько книг, обучающих работе в 3dsmax 6 и прочитал их. И больше всего знаний мне дала книга, построенная по принципу «делаем практические занятия и по ходу разбираемся с программой». В отличие от остальных, сухо рассказывающих обо всех функциях 3dsmax без практических примеров.

Когда в начале этого года я сел за курс по Акшуре, я решил пойти сразу двумя путями и взялся за два продукта. Первый был набором видео по всем Акшурным функциям, а второй демонстрировал, как я за 5 часов делаю с нуля прототип интернет-магазина. К счастью, первый я подзабросил (к счастью, потому что на подходе восьмая версия программы, лучше браться уже за неё), а второй довёл до конца.

Как происходила запись. Я просто сел за привычную работу, только на этот раз выполнял её не молча, а комментируя свои действия в стоящий на столе микрофон (цена вопроса — 10к, мне он достался от друга). За основу я взял проект, который выполнил буквально за месяц до старта записи: интернет-магазин принтеров и картриджей (это был hp). Конечно, я его сильно упростил для курса. Захват экрана я производил с помощью программы под названием Camtasia.

Где-то через семь часов записи, растянувшихся на неделю, пятичасовой курс был готов. Встал вопрос, как продавать? Здесь можно написать очень много текста о поисках и экспериментах, но я ограничусь описанием финального сетапа: площадка для публикации инфопродуктов knowhow (5к в месяц за использование) в связке с платёжным гейтом PayU. Договор заключался и с теми, и с другими. Белые деньги должны были поступать на ИПшный счёт. И, собственно, поступают.

Дальше я пошёл в свою группу по Акшуре в контакте, в которой на тот момент было чуть меньше 4к участников и сказал в одном из постов: «Народ, курс, который вы были готовы купить, согласно предыдущим опросам, готов! Налетайте!» Ну, конечно, я это по-другому сформулировал. И это мне принесло целых ноль продаж. Я анонсировал курс ещё пару раз, в том числе и в паблике Проектората, с тем же результатом. Цена вопроса — 5 000 рублей. Желающих приобрести — никого. Получилось сделать две продажи вручную через знакомых, которые меня знали и в принципе ждали этого курса.

Страница, продающая курс, на момент первых попыток выглядела ужасно, но я и не планировал убеждать тех, кто постоянно задаёт мне вопросы по Акшуре в личных сообщениях, в том, что он стоит их внимания. А зря.

В итоге пришлось делать лэндинг. Для этого воспользовался Тильдой. С Тильдой была отдельная история, достойная своей статьи. Закончилось всё хорошо, и за полтора часа моей работы продающая страница курса красовалась на домене третьего уровня Проектората. На лэндинге даже был отзыв, который я получил от одного из первых покупателей. Для того, чтобы не делать специальных продающих роликов, я просто выложил первый и двенадцатый уроки в открытый доступ. И это начало работать! И принесло мне ещё целых… две продажи. На этот раз покупатели образовались из моего канала на ютубе.

Параллельно с этими делами я периодически общался со знакомыми инфобизнесменами, которые посмеивались над моими глупыми продажами «в лоб» (сравнивая их с разбрасыванием картошки по Невскому в надежде, что она прорастёт) и делились наукой о том, как надо продавать инфопродукты. В двух словах: сначала продаём что-нибудь супердешёвое или бесплатное, затем собираем аудиторию на паре-тройке вебинаров, организовываем подписку на рассылки, продаём уже что-нибудь подороже и в самом конце, когда все уже разогретые и информированные, выкатываем им полноценный курс. И, главное, не нужно продавать это как «Курс по прототипированию в Акшуре». Продавать надо как «Курс, который обучит вас навыкам, с помощью которых вы сможете зарабатывать кучу денег на фрилансе». В общем, инфобизнесмена из меня не получилось, т.к. я точно знал, что из тех людей, кто пройдёт курс, зарабатывать что-то на фрилансе будут единицы, и то это никак не будет связано с тем, чему я обучаю. Это знание мне и помешало.

В конце концов я дал рекламу в Контакте и в Директе. Контакт принял моё объявление к показу с седьмой попытки. Причём, седьмая версия объявления идентична пятой версии, которую отказались показывать. Сначала не нравилось изображение (в итоге просто вставил фотографию своей физиономии), затем формулировки. В итоге от рекламного объявления осталось только объявление. Показывал я его в тех группах, где водились UX-дизайнеры, аудитория составляла около 15к человек. Рекомендуемая цена перехода была около сорока рублей. Поэтому первые 2,5к рублей я слил за пару часов, пока не решил попробовать уменьшить рекомендуемую цену до 20 рублей, затем до 10 рублей, а сейчас и вовсе реклама крутится за 3 рубля за клик. Эффективность по охвату и показам упала, но не на порядок, в отличие от цены. Реклама в Контакте принесла мне ещё 3 покупателей, соответственно деньги на неё отбились с лихвой.

Про Директ мне сказать толком нечего. Бюджет в 1000 рублей по набору ключевых фраз, авторов которых может заинтересовать прототипирование в седьмой Акшуре, тратится за неделю с большим трудом.

Итого: за всё время я сделал 7 продаж (но не собираюсь на этом останавливаться) и едва отбил те часы, которые потратил на создание самого курса. Зато уже ясно, как и о чём запускать следующий курс.

Резюме
Во-первых, я, как начинающий продавец собственного продукта в электронном виде, столкнулся с тем, что не понимал, какими сервисами пользоваться, что делать и как продавать. И активный поиск в Яндексе и Гугле не вывел меня ни на одну команду, которая смогла бы взять меня с моим продуктом и направить на путь истинный за реферальное или абонентское вознаграждение. Сейчас я уже легко могу найти и сервисы и команды, но только потому что апгрейднулся из совсем новичка в того, кто чуть-чуть в теме. Отсюда: ниша помощи начинающим инфобизнесменам пока не очень хорошо умеет работать с целевой аудиторией. Всем интересны уже состоявшиеся авторы.

Во-вторых, продавать сейчас легче не прикладные материалы по тем или иным профессиям, а профессии целиком под соусом личной выгоды от этой профессии. Все спрашивают о полноценном курсе по проектированию интерфейсов, но мало кто будет интересоваться деталями и частностями: как ускорять работу в специализированном софте или какие бизнес-процессы используют те или иные сложившиеся специалисты рынка. На слуху картонные персонажи, юзкейсы и Купер с Раскиным. А формализацией функциональных требований или тем, как писать ТЗ, интересоваться будут единицы, которые уже понюхали пороху. И это логично. А мне урок на будущее.

В-третьих, сам факт создания чего-то автономного на продажу, а затем и его продажи, дал мне нового опыта и эмоций. Также я смог сравнить продажи инфопродуктов с продажами услуг проектирования (это то, чем я занимаюсь по жизни) и понять, какие куски где можно позаимствовать."
"Привет, Хабр!
 
В конце прошлой недели вышла GoLand 2018.1! Для нашей команды этот релиз особенный, — это первое крупное обновление IDE с момента ее запуска четыре месяца назад. Подсказки при редактировании, и навигация по коду, которыми наша команда гордится, стали еще более умными и удобными. Интеграция со многими инструментами доведена до ума. В обновлении поддерживаются частичные коммиты Git, интеграция с Dep, возможность отладки локальных процессов Go, улучшена поддержка Docker Compose, добавлены подсказки при редактировании файлов Kubernetes, и многое другое. 



Ниже подробнее о том, что попало в релиз.

Рефакторинги

В этом обновлении мы добавили рефакторинг Move. С его помощью можно быстро переместить в другой файл в пределах одного пакета любой символ верхнего уровня:



Алгоритм предложения имен, используемый Extract Variable, теперь учитывает контекст и избегает коллизий имен.

Рефакторинг Rename для глобальных символов теперь работает гораздо быстрее (как и Find Usages).

Автодополнение

Булево выражение, подсказанное комплишеном, теперь можно выбрать с одновременным отрицанием, нажав ""!"":



Если курсор расположен справа от оператора возврата внутри функции, автодополнение предлагает значения по умолчанию в соответствии с типом значения, возвращаемого функцией:



В новой версии добавились два шаблона Postfix Completion.

• Новый шаблон «.if» преобразует булево выражение в оператор if:



• Новый шаблон «.p» подставляет в начало выражения оператор указателя.

Intention actions

В обновлении появилось несколько новых Intention actions, например Flip for binary expressions, Negate recursively и Negate для булевых выражений:



Помимо Negate, для выражения if теперь также можно использовать Invert:



Другие вспомогательные инструменты

Вот еще некоторые улучшения, которые помогут вам в работе:
 

Механизм автоматического импорта стал умнее и теперь срабатывает, только если полученный код компилируется без ошибок. 
Если курсор находится на вызове из цепочки или на строковом литерале, по нажатию Enter IDE автоматически форматирует полученный код.
Редактор теперь может удалять операторы импорта для неиспользуемых пакетов прямо во время работы в редакторе. Этот параметр называется Optimize imports on the fly. Его можно включить в разделе Settings | Go | Imports.
Всплывающее окно Quick Documentation теперь учитывает примеры функций и включает их в состав документации. Если кликнуть на имя функции-примера, IDE откроет Scratch File с кодом этой функции:



Scratch Files

Эти самые Scratch Files, с которыми вы, возможно, уже успели поэкспериментировать, предоставляют сеанс редактирования в стиле Go Playground с полной поддержкой IDE. В новой версии они тоже стали лучше. Во-первых, в Scratch File, созданный из выделенного кода Go, теперь автоматически добавляются все необходимые импорт выражения. Во-вторых, такие файлы теперь создаются из шаблонов, которые можно настроить в разделе Settings | Editor | File and Code Templates.

Отладчик

В новой версии отладчик можно прикреплять к локально выполняемым процессам. Для этого достаточно кликнуть Run в главном меню и выбрать Attach to Local Process:



IDE предложит выбрать процесс для отладки:



После выбора процесса открывается окно инструмента Debugger и начинают действовать точки останова.

Dep

Еще одна важная новость — в последнем обновлении появилась поддержка инструмента dep для управления зависимостями.

Когда импортируется существующий проект dep, IDE обнаруживает dep и просит включить интеграцию с ним.

Если при работе с проектом dep открыть файл, в котором есть неразрешенный оператор импорта, IDE предлагает quick-fix, запускающий dep ensure:



Поддержка Go 1.10

Все инструменты IDE для работы с кодом обновлены и полностью поддерживают все возможности Go 1.10.

Стиль кода

Среди параметров Code Style появилось несколько новых: Use back quotes for imports, Add parentheses for a single import и Add leading space to comments.

VCS

Еще одно крупное новшество в последнем обновлении — наконец-то появилась поддержка частичных коммитов Git.

Теперь можно выбирать, какие именно изменения в файле необходимо включить в коммит:



Эти отдельные изменения внутри файла можно распределить по разным Changesets. Для этого нужно кликнуть на маркер изменений, расположенный на левой панели редактора:



Во всплывающем окне Git Branches появились новые действия для перебазирования: Abort Rebase, Continue Rebase и Skip Commit.

И наконец, окно инструмента VCS теперь позволяет группировать изменения по репозиториям.

Пользовательский интерфейс

Предварительный просмотр во всплывающем окне Replace in Path теперь работает, даже если использовано регулярное выражение.

Любую папку из окна инструмента Project теперь легко открыть в окне терминала. Для этого используется действие Open in Terminal.

Кроме того, IDE теперь правильно обрабатывает дробные коэффициенты масштаба при использовании нескольких мониторов HiDPI.

Производительность

В новой версии можно повысить производительность IDE, ограничив для проекта область индексирования, например, чтобы не индексировать весь GOPATH.

JavaScript/TypeScript

Поддержка фронтэнд-технологий, таких как TypeScript и JavaScript значительно улучшилась благодаря достижениям команды WebStorm.

Вот самые важные изменения:


 Поддержка TypeScript 2.7
 Новый quick-fix Surround with type guard для «unresolved» свойств.
 Рефакторинг Rename для классов также предлагает переименовать файл. Этот рефакторинг теперь можно вызвать через Intention action на классе.
 Если установлен пакет Prettier, в IDE появляется действие Reformat with Prettier.
 Новый рефакторинг Extract a Vue component.
 Стало удобнее работать с менеджерами пакетов. Теперь можно явным образом выбрать npm или Yarn для установки зависимостей и запуска скриптов.
 Если вы уже перешли на Webpack 4, IDE предлагает подсказки для имен параметров в файле конфигурации webpack.
 Скрипты npm теперь можно выполнять прямо из редактора с помощью иконок на левой панели, подобно тестам.

Разное

Наконец, нельзя не упомянуть новый плагин для Kubernetes:



Подробнее о работе с плагином можно узнать в посте в блоге IntelliJ IDEA.

Вот такой длинный список. Надеемся, что вам пригодится что-нибудь из этого. А если нет, расскажите нам, чего вам не хватает или что хотелось бы добавить.

Подробнее узнать об этих и других изменениях можно на странице What’s New.

Скачать обновление можно на странице загрузки или через приложение Toolbox App.

  Как всегда, будем рады вашим отзывам и постараемся ответить на любые вопросы.

Приятной разработки!"
